{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import show\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate, train_test_split\n",
    "\n",
    "\n",
    "from statistics import mean, stdev, median, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266074</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>0.207175</td>\n",
       "      <td>-0.849179</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>1.685209</td>\n",
       "      <td>-0.232828</td>\n",
       "      <td>0.465775</td>\n",
       "      <td>-0.154186</td>\n",
       "      <td>1.867521</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266074</td>\n",
       "      <td>0.415367</td>\n",
       "      <td>0.089814</td>\n",
       "      <td>-0.685010</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.930856</td>\n",
       "      <td>0.295677</td>\n",
       "      <td>-0.586191</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>-0.873779</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.105308</td>\n",
       "      <td>-0.079257</td>\n",
       "      <td>0.239183</td>\n",
       "      <td>-1.152363</td>\n",
       "      <td>-0.989576</td>\n",
       "      <td>0.107265</td>\n",
       "      <td>-0.346080</td>\n",
       "      <td>-2.179147</td>\n",
       "      <td>-1.463808</td>\n",
       "      <td>0.413480</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.128929</td>\n",
       "      <td>0.022808</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.837775</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>1.269960</td>\n",
       "      <td>0.257927</td>\n",
       "      <td>-0.089700</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>1.118524</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.054866</td>\n",
       "      <td>0.226939</td>\n",
       "      <td>0.320980</td>\n",
       "      <td>-0.905841</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-1.553729</td>\n",
       "      <td>0.673182</td>\n",
       "      <td>-2.534876</td>\n",
       "      <td>-1.307901</td>\n",
       "      <td>-1.592651</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.266074  0.109171  0.207175 -0.849179  0.261718  1.685209 -0.232828   \n",
       "1  0.266074  0.415367  0.089814 -0.685010  0.261718 -0.930856  0.295677   \n",
       "2  2.105308 -0.079257  0.239183 -1.152363 -0.989576  0.107265 -0.346080   \n",
       "3 -0.128929  0.022808  0.192950  0.837775  0.261718  1.269960  0.257927   \n",
       "4 -0.054866  0.226939  0.320980 -0.905841  0.261718 -1.553729  0.673182   \n",
       "\n",
       "         7         8         9    10  \n",
       "0  0.465775 -0.154186  1.867521  0.0  \n",
       "1 -0.586191  0.251173 -0.873779  1.0  \n",
       "2 -2.179147 -1.463808  0.413480  1.0  \n",
       "3 -0.089700  0.001721  1.118524  1.0  \n",
       "4 -2.534876 -1.307901 -1.592651  1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data. csv file should be in the same folder as the notebook for this to work, otherwise\n",
    "# give data path.\n",
    "features = np.loadtxt(\"features.csv\")\n",
    "labels = np.loadtxt(\"labels.csv\")\n",
    "data1 = pd.DataFrame(data = features)\n",
    "data2 = pd.DataFrame(data= labels, columns=[10])\n",
    "data  = pd.concat([data1, data2], axis = 1)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0.154980</td>\n",
       "      <td>0.336855</td>\n",
       "      <td>0.068476</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.224934</td>\n",
       "      <td>0.257927</td>\n",
       "      <td>-0.299115</td>\n",
       "      <td>-1.058449</td>\n",
       "      <td>-0.222935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0.105604</td>\n",
       "      <td>-0.149918</td>\n",
       "      <td>0.438342</td>\n",
       "      <td>0.934659</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.307984</td>\n",
       "      <td>-0.006326</td>\n",
       "      <td>0.386909</td>\n",
       "      <td>-0.746634</td>\n",
       "      <td>-0.157415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>-0.425181</td>\n",
       "      <td>-0.220579</td>\n",
       "      <td>0.306755</td>\n",
       "      <td>0.496637</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.806282</td>\n",
       "      <td>0.031425</td>\n",
       "      <td>2.043238</td>\n",
       "      <td>1.217798</td>\n",
       "      <td>-0.637896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.305451</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>-0.410380</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-1.304580</td>\n",
       "      <td>0.824183</td>\n",
       "      <td>0.709458</td>\n",
       "      <td>0.968347</td>\n",
       "      <td>-1.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.178304</td>\n",
       "      <td>-0.338346</td>\n",
       "      <td>0.459680</td>\n",
       "      <td>1.402460</td>\n",
       "      <td>0.797987</td>\n",
       "      <td>0.107265</td>\n",
       "      <td>-1.667344</td>\n",
       "      <td>0.404306</td>\n",
       "      <td>0.625350</td>\n",
       "      <td>1.375142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "879  0.154980  0.336855  0.068476  0.021525  0.261718 -0.224934  0.257927   \n",
       "877  0.105604 -0.149918  0.438342  0.934659  0.261718 -0.307984 -0.006326   \n",
       "374 -0.425181 -0.220579  0.306755  0.496637  0.261718 -0.806282  0.031425   \n",
       "140 -0.116585  0.305451  0.036468 -0.410380  0.261718 -1.304580  0.824183   \n",
       "94  -0.178304 -0.338346  0.459680  1.402460  0.797987  0.107265 -1.667344   \n",
       "\n",
       "            7         8         9  \n",
       "879 -0.299115 -1.058449 -0.222935  \n",
       "877  0.386909 -0.746634 -0.157415  \n",
       "374  2.043238  1.217798 -0.637896  \n",
       "140  0.709458  0.968347 -1.434343  \n",
       "94   0.404306  0.625350  1.375142  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(data.iloc[:, :10], data.iloc[:,10:], test_size = 0.2)\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features = np.asarray(X_train)\n",
    "# test_features = np.asarray(X_test)\n",
    "# val_features = np.asarray(X_val)\n",
    "# train_labels = np.asarray(y_train)\n",
    "# test_labels = np.asarray(y_test)\n",
    "# val_labels = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features = features[:800]\n",
    "# train_labels = labels[:800]\n",
    "# test_features = features[800:]\n",
    "# test_labels = labels[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum(x,y):\n",
    "    min = np.argmin(y)\n",
    "\n",
    "    return x[min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum7(p,q,r,s,x,y,z):\n",
    "    min = np.argmin(z)\n",
    "\n",
    "    return p[min],q[min],r[min],s[min],x[min], y[min], z[min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels[0]\n",
    "# dtrain[0][0]\n",
    "# len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtrain = np.zeros(shape =(len(train_labels),2))\n",
    "# dval = np.zeros(shape = (len(val_labels),2)) \n",
    "# dtest = np.zeros(shape = (len(test_labels),2))\n",
    "\n",
    "# for i in range(len(train_labels)):\n",
    "# #     print(i)\n",
    "# #     print(dtrain[0][int(train_labels[i])])\n",
    "# #     print(f)\n",
    "#     dtrain[i][int(train_labels[i])] = 1\n",
    "\n",
    "# for i in range(len(test_labels)):\n",
    "#     dtest[i][int(test_labels[i])] = 1\n",
    "    \n",
    "# for i in range(len(val_labels)):\n",
    "#     dval[i][int(val_labels[i])] = 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Selection - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kalya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kalya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kalya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kalya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kalya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kalya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# nHiddenLayers = 1\n",
    "# nHiddenNodes =2\n",
    "# numOutputs = 10\n",
    "# eta = 1\n",
    "# iter = 100\n",
    "# prec = 1.6\n",
    "#print(xtrain.shape)\n",
    "\n",
    "\n",
    "hidden = [1,2,5]\n",
    "nodes = [2,5,10]\n",
    "lr =[0.1,1]\n",
    "af =['tanh', 'relu']\n",
    "solver =['sgd','adam']\n",
    "\n",
    "a = []\n",
    "b = []\n",
    "c = []\n",
    "d =[]\n",
    "e=[]\n",
    "f= []\n",
    "g =[]\n",
    "h =[]\n",
    "std =[]\n",
    "y =[]\n",
    "x = []\n",
    "\n",
    "\n",
    "\n",
    "for i in hidden:\n",
    "    for j in nodes:\n",
    "        for k in lr:\n",
    "            for l in af:\n",
    "                for m in solver:\n",
    "                    hid = [j for n in range(i)]\n",
    "                    classifier  = MLPClassifier(hidden_layer_sizes= hid, activation = l, learning_rate_init = k, learning_rate = 'adaptive',max_iter=1000,solver = m)\n",
    "                    cvs = cross_validate(classifier, X_train, y_train.values.ravel(), cv = 10, scoring='accuracy', return_train_score = True)\n",
    "                    test_err = 1-cvs['test_score']\n",
    "                    train_err = 1 - cvs['train_score']\n",
    "                    evsm_test = test_err.mean()\n",
    "                    evsm_train = train_err.mean()\n",
    "                    temp = stdev(test_err)\n",
    "                    temp2 = evsm_test + temp\n",
    "                    a.append(evsm_test)\n",
    "                    b.append(evsm_train)\n",
    "                    std.append(2*temp)\n",
    "                    c.append(temp2)\n",
    "                    d.append(len(hid))\n",
    "                    e.append(j)\n",
    "                    f.append(k)\n",
    "                    g.append(l)\n",
    "                    h.append(m)          \n",
    "                    \n",
    "                    y.append(evsm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal no of hidden layers = 1\n",
      "The optimal no of hidden nodes per hidden Layer = 10\n",
      "The optimal Learning rate = 0.1\n",
      "The optimal Activation function is relu\n",
      "The optimal solver is adam\n"
     ]
    }
   ],
   "source": [
    "b_hl, b_hn, b_lr, b_af, b_s, t_error,b_error = minimum7(d,e,f,g,h,b,c)\n",
    "print('The optimal no of hidden layers = ' + str(b_hl))\n",
    "print('The optimal no of hidden nodes per hidden Layer = ' + str(b_hn))\n",
    "print('The optimal Learning rate = ' + str(b_lr))\n",
    "print('The optimal Activation function is ' + b_af)\n",
    "print('The optimal solver is ' + b_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy obtained with my best model = 0.77\n"
     ]
    }
   ],
   "source": [
    "b_hid = [b_hn for n in range(b_hl)]\n",
    "b_classifier  = MLPClassifier(hidden_layer_sizes= b_hid, activation = b_af, learning_rate_init = b_lr, learning_rate = 'adaptive',max_iter=1000,solver = b_s, random_state = 100)\n",
    "b_classifier.fit(X_train, y_train.values.ravel())\n",
    "y_pred = b_classifier.predict(X_test)\n",
    "nn_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('The testing accuracy obtained with my best model = ' + str(nn_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hyperparameters for my final neural network are:\n",
    "# No of Hidden Layers = 1, No of hidden nodes = 10, Learning Rate = 0.1, no of iterations/epochs = 1000, solver = ‘adam’, activation function = ‘relu’\n",
    "# To make the algorithm simple, I used rectangular weight matrix i.e. the number of nodes in all hidden layers is same\n",
    "# I used the following grid for the Grid Search method to select the best hyperparameters:\n",
    "# 1.\thidden = [1,2,5]\n",
    "# 2.\tnodes = [2,5,10]\n",
    "# 3.\tlr =[0.1,1]\n",
    "# 4.\taf =['tanh', 'relu']\n",
    "# 5.\tsolver =['sgd','adam']\n",
    "# I tried every combination of the above (72 combinations) and calculated the cross validation error. Then, I picked the hyperparameters which gave the least cross validation error.\n",
    "# I applied the best model on the test dataset and got 76.5 percent accuracy\n",
    "# While doing the search, I got a few convergence warning which says that the no of iterations  = 1000 is not enough for the model to converge. This may be due to the 0.1 learning rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q) 2) b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hoeffding Bound for 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta1 = 0.05\n",
    "n_test = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eb(n_test, delta, t, etest):\n",
    "    if t == \"Markov\":\n",
    "        return etest/delta\n",
    "    elif t == \"Chebyshev\":\n",
    "        return sqrt(1/(4*n_test*delta))\n",
    "    else:\n",
    "        return sqrt((1/(2*n_test))*log(2/delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09603227913199208"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb = eb(n_test, delta1, \"Hoeffding\", 1-nn_accuracy)\n",
    "hb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The concentration bound obtained at 95% confidence interval using Hoeffding bound is 0.096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Given Confidence Interval</th>\n",
       "      <th>Type of bound</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Obtained Accuracy</th>\n",
       "      <th>Obtained Error</th>\n",
       "      <th>e</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>95</td>\n",
       "      <td>Hoeffding</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.096032</td>\n",
       "      <td>0.326032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classifier  Given Confidence Interval Type of bound  Delta  \\\n",
       "0  Neural Network                         95     Hoeffding   0.05   \n",
       "\n",
       "   Obtained Accuracy  Obtained Error         e         D  \n",
       "0               0.77            0.23  0.096032  0.326032  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bound = [[\"Neural Network\", 95, \"Hoeffding\", delta1, nn_accuracy, 1-nn_accuracy, hb, 1-nn_accuracy+hb]]\n",
    "columns = [\"Classifier\", \"Given Confidence Interval\", \"Type of bound\", \"Delta\", \"Obtained Accuracy\", \"Obtained Error\", \"e\", \"D\"]\n",
    "table_bound = pd.DataFrame(data = bound, columns = columns) \n",
    "table_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q) 5) c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error obtained with my best model = 0.17041666666666666\n"
     ]
    }
   ],
   "source": [
    "print('The training error obtained with my best model = ' +str(t_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01597222222222221\n",
      "The testing accuracy obtained with the model that has lower training error = 0.755\n"
     ]
    }
   ],
   "source": [
    "b_hl2, b_hn2, b_lr2, b_af2, b_s2, error,t_error2 = minimum7(d,e,f,g,h,c,b)\n",
    "print(t_error2)\n",
    "b_hid2 = [b_hn2 for n in range(b_hl2)]\n",
    "classifier2  = MLPClassifier(hidden_layer_sizes= b_hid2, activation = b_af2, learning_rate_init = b_lr2, learning_rate = 'adaptive',max_iter=1000,solver = b_s2, random_state = 100)\n",
    "classifier2.fit(X_train, y_train.values.ravel())\n",
    "y_pred2 = classifier2.predict(X_test)\n",
    "nn_accuracy2 = accuracy_score(y_test, y_pred2)\n",
    "print('The testing accuracy obtained with the model that has lower training error = ' + str(nn_accuracy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am getting different results (accuracy) every time I run my neural network because of \n",
    "# 1)\tRandom initialization of weights \n",
    "# 2)\tRandomness in the training data (I set shuffle = True in the MLPClassifier)\n",
    "# 3)\tDue to the adaptive Learning Rate (I set Learning Rate = ‘adaptive’ in the MLP Classifier)\n",
    "# 4)\tMultiple Local Minima (in case of Non-Convex cost functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nHiddenLayers = 1\n",
    "# # nHiddenNodes =8\n",
    "# numOutputs = 2\n",
    "# iter = 10\n",
    "# prec = 0.5\n",
    "# a =[]\n",
    "# b =[]\n",
    "# c =[]\n",
    "# weights =[]\n",
    "# d =[]\n",
    "# e =[]\n",
    "\n",
    "# for i in hiddenLayers:\n",
    "#     for j in hiddenNodes:\n",
    "#         for k in eta:\n",
    "#             NN = Neural_Network(np.asarray(train_features), np.asarray(dtrain), np.asarray(test_features), np.asarray(dtest), i, j, numOutputs, k, iter,prec)\n",
    "#             w, epoch, obj_training, mis_training, obj_testing, mis_testing = NN.train()\n",
    "#             a.append(i)\n",
    "#             b.append(j)\n",
    "#             c.append(k)\n",
    "#             weights.append(w)\n",
    "#             d.append(mis_testing[:-1])\n",
    "#             mp.scatter(epoch,mis_testing, s  = 7)\n",
    "#             mp.xlabel('EPoch')\n",
    "#             mp.ylabel('Number of misclassifications of Testing data')\n",
    "#             mp.title(str([i,j,k]))\n",
    "#             mp.show()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
