{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5],\n",
       "       [0.5, 1.5, 0.5],\n",
       "       [1.5, 0.5, 0.5],\n",
       "       [1.5, 1.5, 0.5]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =[[0.5,0.5, 0.5],[0.5,1.5, 0.5],[1.5,0.5, 0.5],[1.5,1.5, 0.5]]\n",
    "y=[0,1,1,0]\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "\n",
    "# import numpy as np\n",
    "# #np.random.seed(100)\n",
    "\n",
    "\n",
    "# # Sigmoid is the activation Function\n",
    "# def af(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def af_derivative(p):\n",
    "#     return af(p) * (1 -af(p))\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, ep = 0):\n",
    "#         #self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         self.ep = ep\n",
    "#         #self.train()\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "#         self.data = newdata\n",
    "#         self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}] #create the weights from the inputs to the first layer\n",
    "#         for i in range(self.nLayers):\n",
    "#             self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers > 0:\n",
    "            \n",
    "#             self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)}) #create weights from final layer to output node\n",
    "#         #return self.weights\n",
    "        \n",
    "        \n",
    "#     def train(self):\n",
    "        \n",
    "\n",
    "#         print(self.data)\n",
    "# #         #temp_weights = self.weight_initialization()\n",
    "# #         print(self.weights)\n",
    "#         temp_eta = self.eta\n",
    "# #         temp2 = mse(self.data, self.labels, self.weights, self.nLayers + 1, self.nNodes)\n",
    "# #         print(temp2)\n",
    "# #         print(f) \n",
    "#         e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "\n",
    "#         cos = 100000000\n",
    "# #         #epd = 10000000\n",
    "#         while cos >= 0.05:\n",
    "#             #print(cos)\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 #print(i)\n",
    "#                 self.backprop(self.labels[i], self.data[i]) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "# #                 print('\\n')\n",
    "# #                 print(self.weights)\n",
    "# #                 print(f)\n",
    "\n",
    "\n",
    "#             cos = mse(self.data, self.labels, self.weights, self.nLayers + 1,self.nNodes)\n",
    "# #             epoch.append(e)\n",
    "# #             obj.append(cos)\n",
    "# #             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 cos = 100000000\n",
    "# #                 self.weights = temp_weights\n",
    "# #                 print(temp_weights)\n",
    "                \n",
    "#                 if self.eta <= 0.00001:                    \n",
    "#                     self.eta = temp_eta  \n",
    "# #                     obj =[]\n",
    "# #                     epoch = []\n",
    "# #                     e = 0\n",
    "# #                     cos = 100000000\n",
    "#                     self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}]\n",
    "#                     for i in range(self.nLayers):\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)})\n",
    "#                     if self.nLayers >= 0:\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)})                    \n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "#                 #print(g)\n",
    "#         #print(self.weights)\n",
    "#         return self.weights   \n",
    "       \n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "        \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers + 1][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         return q\n",
    "        \n",
    "#     def feedforward(self, data):\n",
    "#         r =[]\n",
    "#         prev = data\n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.dot(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         p = np.dot(self.weights[self.nLayers + 1][\"weights\"][0], l)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         t.append(s)        \n",
    "        \n",
    "#         return t,r, q\n",
    "\n",
    "#     def backprop(self, d, data):\n",
    "#         der = []\n",
    "#         t,r, q= self.feedforward(data)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         #q = self.predict(data)\n",
    "        \n",
    "#         for i in range(self.nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(self.nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = []\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[self.nLayers][0]))\n",
    "#         diff.append(d - q)\n",
    "#         der.append(s)\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer = self.weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(self.weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(self.weights[i + 1]['weights'])):\n",
    "#                         error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff[0])\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "# #         print('\\n')\n",
    "#         #print(weights)\n",
    "#         #print(f)\n",
    "#         for j in range(len(self.weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': array([[ 0.08680988, -0.44326123, -0.15096482],\n",
      "       [ 0.68955226, -0.99056229, -0.75686176]])}, {'weights': array([[0.34149817, 0.65170551]])}]\n",
      "0.01559470829530992\n",
      "[0.5 0.5 0.5]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-284b81d87434>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[0mprec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnLayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnNodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnOut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-284b81d87434>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[1;31m#print(i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;31m#print(len(self.data[i]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-284b81d87434>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(self, d, data)\u001b[0m\n\u001b[0;32m    252\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m's'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m's'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 \u001b[0mlayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "\n",
    "\n",
    "# # Rectified linear Unit Activation Function\n",
    "# def af(t):\n",
    "#     if t >= 0: \n",
    "#         return t\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# # Its derivative\n",
    "# def af_derivative(p):\n",
    "#     if p >= 0:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# Sigmoid is the activation Function\n",
    "def af(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "def af_derivative(p):\n",
    "    return p * (1 -p)\n",
    "\n",
    "# def decision(x):\n",
    "#     if x >= 0.5:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "def mse_misclassifications(x, d, w, nLayers, nNodes):\n",
    "    c = 0\n",
    "    count = 0\n",
    "    n = len(x)\n",
    "    for i in range(0,n):\n",
    "        prev = x[i]             \n",
    "        for j in range(nLayers):\n",
    "            u =[]\n",
    "            p =[]\n",
    "            for k in range(nNodes):\n",
    "                t = np.dot(w[j]['weights'][k], prev)\n",
    "                u.append(t)\n",
    "            for l in u:\n",
    "                p.append(af(l))\n",
    "            #p.append(1)\n",
    "            prev = np.asarray(p)\n",
    "\n",
    "        \n",
    "        y = af(np.dot(w[nLayers][\"weights\"][0], prev))\n",
    "        if np.any(d[i] - y):\n",
    "            count += 1\n",
    "\n",
    "        c += np.linalg.norm(d[i] - y)**2      \n",
    "\n",
    "    return c/n, count\n",
    "\n",
    "\n",
    "\n",
    "#np.random.seed(100)\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, prec = 0):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        self.nLayers = numLayers\n",
    "        self.nNodes = numNodes\n",
    "        self.numOutputs = numOutputs\n",
    "        self.eta = eta\n",
    "        self.temp_eta = eta\n",
    "        self.maxIt = maxIter\n",
    "        self.prec = prec\n",
    "        #self.train()\n",
    "        #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "#         self.data = newdata\n",
    "        self.weights = [{\"weights\":np.random.uniform(low =-1, high = 1, size = (self.nNodes, len(self.data[0])))}] \n",
    "        for i in range(self.nLayers):\n",
    "            self.weights.append({\"weights\":np.random.uniform(low =-1, high = 1, size = (self.nNodes,self.nNodes))})             \n",
    "        if self.nLayers >= 0:            \n",
    "            self.weights.append({\"weights\":np.random.uniform(low =-1, high = 1, size = (self.numOutputs,self.nNodes))})\n",
    "        self.temp_weights = self.weights\n",
    "         \n",
    "        \n",
    "    def train(self):\n",
    "        print(self.weights)\n",
    "#         return self.weights\n",
    "        #print(self.weights[0]['weights'][0])\n",
    "        \n",
    "        temp_weights = self.weights\n",
    "        temp_eta = self.temp_eta\n",
    "        temp2, temp3 = mse_misclassifications(self.data, self.labels, self.weights, self.nLayers + 1, self.nNodes)\n",
    "        e = 0\n",
    "        obj =[]\n",
    "        epoch = []\n",
    "        mis = []\n",
    "        obj.append(temp2)\n",
    "        mis.append(temp3)\n",
    "        cos = 100000000\n",
    "#         while e < self.maxIt:\n",
    "#             #print(\"K\")\n",
    "        while e <= self.maxIt:\n",
    "            e += 1\n",
    "            prev = cos\n",
    "\n",
    "            i = 0\n",
    "            while i < len(self.data):\n",
    "                #print(i)\n",
    "                #print(len(self.data[i]))\n",
    "                self.backprop(self.labels[i], self.data[i]) \n",
    "                for m in range(len(self.weights)):\n",
    "                    for j in range(len(self.weights[m]['weights'])):\n",
    "                        for k in range(len(self.weights[m]['weights'][j])):\n",
    "                            self.weights[m]['weights'][j][k] += self.eta *self.weights[m]['g'][j][k]\n",
    "                \n",
    "                i += 1\n",
    "#             print(self.weights)\n",
    "#             print(f)\n",
    "\n",
    "            cos, misc = mse_misclassifications(self.data, self.labels, self.weights, self.nLayers + 1,self.nNodes)            \n",
    "            epoch.append(e)\n",
    "            obj.append(cos)\n",
    "            mis.append(misc)\n",
    "#             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 cos = 100000000\n",
    "# #                 self.weights = temp_weights\n",
    "# #                 print(temp_weights)\n",
    "                \n",
    "#                 if self.eta <= 0.00001:                    \n",
    "#                     self.eta = temp_eta  \n",
    "# #                     obj =[]\n",
    "# #                     epoch = []\n",
    "# #                     e = 0\n",
    "# #                     cos = 100000000\n",
    "#                     self.weights = [{\"weights\":np.random.uniform(low =-1, high = 1, size = (self.nNodes, len(self.data[0])))}] \n",
    "#                     for i in range(self.nLayers):\n",
    "#                         self.weights.append({\"weights\":np.random.uniform(low =-1, high = 1, size = (self.nNodes,self.nNodes+1))})             \n",
    "#                     if self.nLayers >= 0:            \n",
    "#                         self.weights.append({\"weights\":np.random.uniform(low =-1, high = 1, size = (self.numOutputs,self.nNodes+1))})\n",
    "                     \n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "#                 #print(g)\n",
    "        print(self.weights)\n",
    "        return self.weights, obj, epoch, mis   \n",
    "       \n",
    "\n",
    "    def feedforward(self,x=[]):\n",
    "        #print(x)\n",
    "        prev = x\n",
    "        r =[]      \n",
    "        r.append(prev)\n",
    "        t =[]\n",
    "        for j in range(self.nLayers + 1):\n",
    "            l = []\n",
    "            s = []\n",
    "            for m in range(self.nNodes):\n",
    "                #print(self.weights[j][\"weights\"][m])\n",
    "                s.append(np.matmul(self.weights[j][\"weights\"][m], prev)) \n",
    "            for k in s:\n",
    "                l.append(af(k))\n",
    "            #l.append(1)\n",
    "            prev = np.asarray(l)\n",
    "            t.append(s)\n",
    "            r.append(l)\n",
    "            \n",
    "        s =[]\n",
    "        for i in range(self.numOutputs):\n",
    "            \n",
    "            p = np.matmul(self.weights[self.nLayers + 1][\"weights\"][i], l)\n",
    "            s.append(af(p))\n",
    "        t.append(s)              \n",
    "        return t,r        \n",
    "\n",
    "    def backprop(self, d, data):\n",
    "        der = []  \n",
    "        \n",
    "        t,r = self.feedforward(data)\n",
    "#         print('\\n')\n",
    "#         print(\"t = \" + str(t))\n",
    "#         print(f)\n",
    "#         print('\\n')\n",
    "#         print('r = ' + str(r))\n",
    "        \n",
    "        for i in range(self.nLayers + 1):\n",
    "            a =[]\n",
    "            for m in range(self.nNodes):\n",
    "                a.append(af_derivative(t[i][m]))\n",
    "            der.append(a)\n",
    "\n",
    "#         print(t[self.nLayers + 1])\n",
    "        diff = d - t[self.nLayers + 1][0]\n",
    "#         print(diff)\n",
    "#         print(f)\n",
    "\n",
    "\n",
    "        s =[]\n",
    "        for k in range(self.numOutputs):\n",
    "            s.append(af_derivative(t[self.nLayers + 1][k]))\n",
    "\n",
    "        der.append(s)\n",
    "    \n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            layer = self.weights[i]\n",
    "            errors = []\n",
    "            if i != len(self.weights)-1:\n",
    "                for j in range(len(layer['weights'])):\n",
    "                    error = 0\n",
    "                    \n",
    "                    for k in range(len(self.weights[i + 1]['weights'])):\n",
    "                        #print(self.weights[i + 1]['s'][k])\n",
    "\n",
    "                        error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "                    errors.append(error)\n",
    "\n",
    "                layer['s'] = []\n",
    "                for j in range(len(layer['weights'])):\n",
    "                    layer['s'].append(errors[j]*der[i][j])\n",
    "            else:\n",
    "                errors.append(diff)\n",
    "\n",
    "                layer['s'] = []\n",
    "                for j in range(len(layer['weights'])):\n",
    "#                     print(diff)\n",
    "#                     print(errors[0][j])\n",
    "#                     print(der[i][j])\n",
    "#                     print(f)\n",
    "                    layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Finding the corresponding gradient vector\n",
    "                \n",
    "\n",
    "        for j in range(len(self.weights)):\n",
    "            layer = self.weights[j]\n",
    "            layer['g'] = []\n",
    "            for k in range(len(self.weights[j]['weights'])):\n",
    "                s =[]\n",
    "                for m in range(len(self.weights[j]['weights'][k])):\n",
    "                    print(self.weights[j]['s'][k])\n",
    "                    print(r[j])\n",
    "                    print(f)\n",
    "                    s.append((((r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "                layer['g'].append(s)\n",
    "\n",
    "        print(self.weights)\n",
    "        print(f)\n",
    "\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "\n",
    "nLayers = 0\n",
    "nNodes = 2\n",
    "nOut = 1\n",
    "eta = 1\n",
    "iter = 10000\n",
    "prec = 0.05\n",
    "\n",
    "w= NeuralNetwork(x,y, nLayers, nNodes, nOut, eta, iter, prec).train()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[ 0.08680988, -0.44326123, -0.15096482],\n",
       "       [ 0.68955226, -0.99056229, -0.75686176]]),\n",
       "       array([[0.34149817, 0.65170551]])], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights =[]\n",
    "for i in range(len(w)):\n",
    "    weights.append(w[i]['weights'])\n",
    "\n",
    "weights = np.asarray(weights)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network():\n",
    "    \n",
    "    def __init__(self, x=[[]], y=[], nHiddenLayers = 0, nHiddenNodes =0, numOutputs = 0, eta = 1, iter = 0, prec = 0):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        self.nInputNodes = x.shape[1]\n",
    "        self.nHiddenLayers = nHiddenLayers\n",
    "        self.nHiddenNodes = nHiddenNodes\n",
    "        self.numOutputs = numOutputs\n",
    "        self.eta = eta\n",
    "        self.maxIt = iter\n",
    "        self.prec = prec\n",
    "\n",
    "\n",
    "        self.weights=[np.random.uniform(low = -1, high = 1, size = (self.nHiddenNodes, self.nInputNodes))]\n",
    "        for i in range(self.nHiddenLayers-1):\n",
    "            self.weights.append(np.random.uniform(low =-1, high = 1, size =(self.nHiddenNodes, self.nHiddenNodes))) \n",
    "        self.weights.append(np.random.uniform(low =-1, high = 1, size = (self.numOutputs, self.nHiddenNodes)))\n",
    "\n",
    "        # Sigmoid activation function\n",
    "\n",
    "    def sigmoid(self, s):      \n",
    "        return 1/(1+np.exp(-s))\n",
    "\n",
    "    #derivative of sigmoid\n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def af(self,s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "    \n",
    "    def af_derivative(self,s):\n",
    "        return s * (1 - s)\n",
    "        \n",
    "    \n",
    "#     def decision_A(self,x):\n",
    "#         out =[]\n",
    "# #         print(x.shape)\n",
    "# #         print(f)\n",
    "#         for i in range(x.shape[0]):\n",
    "#             s =np.zeros(x.shape[1])\n",
    "            \n",
    "            \n",
    "#             max = np.argmax(x[i])\n",
    "#             #print(max)\n",
    "\n",
    "#             s[max] = 1\n",
    "#             out.append(s)\n",
    "#         out = np.asarray(out)\n",
    "#         print(out.shape)\n",
    "#         print(f)\n",
    "#         return out\n",
    "\n",
    "    def misclassifications(self, x,y):\n",
    "        count = 0\n",
    "        for i in range(y.shape[0]): \n",
    "            if np.any(x[i]-y[i]):\n",
    "                count += 1\n",
    "                \n",
    "        return count\n",
    "    \n",
    "    def predict(self):\n",
    "        prev = self.data.T\n",
    "        for i in range(len(self.weights)-1):\n",
    "            temp = (np.matmul(self.weights[i], prev))\n",
    "            temp2 = self.sigmoid(temp)\n",
    "            prev = temp2\n",
    "\n",
    "        temp_f = np.matmul(self.weights[self.nHiddenLayers], prev)\n",
    "        temp4 = self.af(np.transpose(temp_f)) \n",
    "        return temp4[:,0]\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "#         print(x)\n",
    "        self.r = []\n",
    "        self.r.append(x)\n",
    "#         print(self.r)\n",
    "#         print(f)\n",
    "        prev = x.T\n",
    "        \n",
    "        for i in range(len(self.weights)-1):\n",
    "#             print(self.weights[i])\n",
    "#             print(prev)\n",
    "            temp = np.matmul(self.weights[i], prev)\n",
    "#             print(temp)\n",
    "            temp2 = self.sigmoid(temp)\n",
    "#             print(temp2)\n",
    "            self.r.append(temp2)\n",
    "#             print(self.r)\n",
    "#             print('\\n')\n",
    "            prev = temp2\n",
    "            \n",
    "#         print(self.weights[self.nHiddenLayers])\n",
    "#         print(prev)\n",
    "        temp_f = np.matmul(self.weights[self.nHiddenLayers], prev)\n",
    "\n",
    "\n",
    "        temp4 =self.af(temp_f.T)\n",
    "        return temp4[0][0]\n",
    "\n",
    "    def backward(self, x, y):\n",
    "        self.delta = []\n",
    "        self.gradient=[]\n",
    "#         print(x)\n",
    "#         print(y)\n",
    "#         print(f)\n",
    "        o = self.feedforward(x)\n",
    "#         print(o)\n",
    "\n",
    "        self.out_error = y - o\n",
    "#         print(self.out_error)\n",
    "#         print(f)\n",
    "\n",
    "\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            if i == 0 and i != len(self.weights)-1:\n",
    "#                 print(temp)\n",
    "#                 print(self.weights[i+1].T)\n",
    "                temp2 = self.weights[i+1].T.dot(temp)\n",
    "#                 print(temp2)\n",
    "\n",
    "#                 print(self.sigmoidPrime(self.r[i+1]))\n",
    "\n",
    "                temp3 = temp2*self.sigmoidPrime(self.r[i+1])\n",
    "#                 print(temp3)\n",
    "\n",
    "                temp4 = (temp3.dot(x))*2/len(self.data)\n",
    "#                 print(temp4)\n",
    "#                 print('w')\n",
    "#                 print(self.weights[i])\n",
    "#                 print((self.eta*temp4*2)/len(self.data))\n",
    "                self.gradient.append(temp4)\n",
    "#                 print(temp4)\n",
    "#                 print(f)\n",
    "#                 print(self.weights[i])\n",
    "                temp = temp3\n",
    "                self.delta.append(temp3)\n",
    "                    \n",
    "            elif i > 0 and i<len(self.weights)-1:\n",
    "                temp2 = self.weights[i+1].T.dot(temp) \n",
    "                temp3 = temp2*self.sigmoidPrime(self.r[i+1])\n",
    "                temp4 = (temp3.dot(self.r[i].T))*2/len(self.data)\n",
    "                temp = temp3\n",
    "                self.delta.append(temp3)\n",
    "                self.gradient.append(temp4)\n",
    "\n",
    "\n",
    "                    \n",
    "            elif i == len(self.weights)-1:\n",
    "#                 print(self.out_error)\n",
    "#                 print(self.af_derivative(o))\n",
    "#                 print(f)\n",
    "                temp = self.out_error*self.af_derivative(o)\n",
    "\n",
    "#                 print(self.weights[i])\n",
    "\n",
    "#                 print(self.r[i].T)\n",
    "                temp2 = (temp*self.r[i].T)*2/len(self.data)\n",
    "                self.delta.append(temp)\n",
    "#                 print(temp2)\n",
    "#                 print((self.eta*temp2*2)/len(self.data))\n",
    "                self.gradient.append(temp2)\n",
    "#                 print(self.weights[i])\n",
    "#                 print('\\n')\n",
    "\n",
    "        self.gradient = self.gradient[::-1]\n",
    "#         print(self.weights[1]+self.gradient[1])\n",
    "#         print(f)\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += self.gradient[i]\n",
    "#         print(self.weights)\n",
    "#         print(f)\n",
    "\n",
    "            \n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "    def train (self):\n",
    "        #print(self.eta)\n",
    "        print(self.weights)\n",
    "        e = 0\n",
    "        obj =[]\n",
    "        epoch = []\n",
    "        mis = []\n",
    "        epoch.append(e)\n",
    "        pred = self.predict()\n",
    "        obj.append(((np.linalg.norm(self.labels - pred))**2)/len(self.data))\n",
    "        mis.append(self.misclassifications(self.labels, pred))\n",
    "        mse = 100000000000\n",
    "        while e <= self.maxIt: \n",
    "            prev = mse\n",
    "#             print(prev)\n",
    "#             print(f)\n",
    "            e += 1\n",
    "            for i in range(len(self.data)):                \n",
    "                self.backward(self.data[i].reshape(1,self.nInputNodes), self.labels[i])\n",
    "#                 print(self.delta)\n",
    "#                 print(f)\n",
    "#             print(self.weights)\n",
    "#             print(f)\n",
    "                \n",
    "#             print('after')\n",
    "#             print(self.weights)\n",
    "            pred = self.predict()\n",
    "\n",
    "            mse = ((np.linalg.norm(self.labels - pred))**2)/len(self.data)\n",
    "#             print(mse)\n",
    "#             print(f)\n",
    "\n",
    "            \n",
    "            obj.append(mse)\n",
    "            epoch.append(e)\n",
    "            mis.append(self.misclassifications(self.labels, pred))\n",
    "            if mse >= prev:\n",
    "                self.eta = 0.8*self.eta\n",
    "            prev = mse\n",
    "        print(self.weights)\n",
    "        return self.weights, epoch, obj, mis\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.652784  ,  0.93321939,  0.9140252 ],\n",
      "       [ 0.19594737,  0.46260151, -0.31922955]]), array([[-0.81588879, -0.07300396]])]\n",
      "[array([[-8.11621696, 10.40447321,  4.69905392],\n",
      "       [-1.50947251,  1.56372164, -0.39740538]]), array([[-12.66107405,  19.65183669]])]\n"
     ]
    }
   ],
   "source": [
    "nHiddenLayers = 1\n",
    "nHiddenNodes =2\n",
    "numOutputs = 1\n",
    "eta = 1\n",
    "iter = 10000\n",
    "prec = 0.5\n",
    "#print(xtrain.shape)\n",
    "NN = Neural_Network(x, y, nHiddenLayers, nHiddenNodes, numOutputs, eta, iter, prec)\n",
    "\n",
    "w, epoch, obj, mis = NN.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize = (20,5))\n",
    "plt.scatter(epoch,obj, s  = 7)\n",
    "plt.plot(epoch,obj)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title('Plot: the number of epochs vs the MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012061924199180599"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.24601978*0.04902827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0500095013157235"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.14644149137233592*0.34149817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (4,) not aligned: 3 (dim 0) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-3db90e7f06a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnewdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse_misclassifications\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-110-552179a62d73>\u001b[0m in \u001b[0;36mmse_misclassifications\u001b[1;34m(x, d, w, nLayers, nNodes)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnNodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m                 \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,) and (4,) not aligned: 3 (dim 0) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "newdata = []\n",
    "for i in range(len(x)):\n",
    "    newdata.append(np.append(x[i],1))     \n",
    "cos, mis = mse_misclassifications(newdata, y, w, 1,2)\n",
    "cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,w):\n",
    "        #Do not change this function header\n",
    "        #print('\\n')\n",
    "        #print(\"Predict Function\")\n",
    "#     newdata = []\n",
    "#     for i in range(len(x)):\n",
    "#         newdata.append(np.append(x[i],1))\n",
    "#     newdata = np.asarray(newdata)\n",
    "    prev = np.append(x,1)\n",
    "    for j in range(nLayers):\n",
    "        #print(prev)\n",
    "        l = []\n",
    "        s = []\n",
    "        for m in range(nNodes):\n",
    "            #print(w[j][\"weights\"][m])\n",
    "            s.append(np.matmul(w[j][\"weights\"][m], prev))\n",
    "        for k in s:\n",
    "            l.append(af(k))\n",
    "        l.append(1)\n",
    "        prev = np.asarray(l)\n",
    "    s =[]\n",
    "    for n in range(nOut):\n",
    "\n",
    "        p = np.dot(prev,w[nLayers][\"weights\"][n])\n",
    "        s.append(p)\n",
    "    q = []\n",
    "    for i in range(len(s)):\n",
    "        q.append(af(s[i]))\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10566471984298263]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p= predict([0.5,0.5, 0.5], w)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5219109581721073"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af(0.0877)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24963934723851425"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af_derivative(0.076)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15617815132940527,\n",
       " 0.39930187620131075,\n",
       " 0.41335189442217146,\n",
       " 0.6881133459690951,\n",
       " 0.41195037138254215,\n",
       " 0.8430785393983047,\n",
       " 0.8361466071009599,\n",
       " 0.048627368891770384,\n",
       " 0.16861064580142782,\n",
       " 0.8434798365239617,\n",
       " -0.12957839763614887]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights =[]\n",
    "for j in range(len(w)):\n",
    "    for k in range(len(w[j]['weights'])):\n",
    "        for m in range(len(w[j]['weights'][k])):\n",
    "            weights.append(w[j]['weights'][k][m])\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6527358278270062],\n",
       " [0.678587063732908],\n",
       " [0.6668809008516015],\n",
       " [0.6864532238463801]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata = []\n",
    "for i in range(len(x)):\n",
    "    newdata.append(np.append(x[i],1))\n",
    "p = []\n",
    "for i in newdata:\n",
    "    p.append(predict(i,w))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 5, 14]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.transpose(np.mat([[0,1,2],[3,4,5]]))\n",
    "print(a.shape)\n",
    "b = np.mat([0,1,2])\n",
    "print(b.shape)\n",
    "np.matmul(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(numpy.array([1,3,4]) < numpy.array([4,6,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "\n",
    "\n",
    "# np.random.seed(100)\n",
    "\n",
    "\n",
    "# # Sigmoid is the activation Function\n",
    "# def af(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def af_derivative(p):\n",
    "#     return af(p) * (1 -af(p))\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         y = af(y)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, ep = 0):\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         self.ep = ep\n",
    "#         #self.train()\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "#         self.data = newdata\n",
    "#         self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}] #create the weights from the inputs to the first layer\n",
    "#         for i in range(self.nLayers-1):\n",
    "#             self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers > 0:\n",
    "            \n",
    "#             self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)}) #create weights from final layer to output node\n",
    "#         #return self.weights\n",
    "        \n",
    "        \n",
    "#     def train(self):\n",
    "        \n",
    "\n",
    "#         print(self.data)\n",
    "#         #temp_weights = self.weight_initialization()\n",
    "#         print(self.weights)\n",
    "#         temp_eta = self.eta\n",
    "#         temp2 = mse(self.data, self.labels, self.weights, self.nLayers, self.nNodes)\n",
    "#         print(temp2)\n",
    "# #         print(f) \n",
    "#         e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "# #         epoch.append(e)\n",
    "# #         obj.append(temp2)\n",
    "#         cos = 100000000\n",
    "# #         #epd = 10000000\n",
    "# #         while e < self.maxIt:\n",
    "#         while cos >= 0.1:\n",
    "#             #print(cos)\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 #print(i)\n",
    "#                 self.backprop(self.labels[i], self.data[i]) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "\n",
    "#             cos = mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes)\n",
    "# #             epoch.append(e)\n",
    "# #             obj.append(cos)\n",
    "# #             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 cos = 100000000\n",
    "# #                 self.weights = temp_weights\n",
    "# #                 print(temp_weights)\n",
    "                \n",
    "#                 if self.eta <= 0.00001:                    \n",
    "#                     self.eta = temp_eta  \n",
    "# #                     obj =[]\n",
    "# #                     epoch = []\n",
    "# #                     e = 0\n",
    "# #                     cos = 100000000\n",
    "#                     self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}]\n",
    "#                     for i in range(self.nLayers-1):\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)})\n",
    "#                     if self.nLayers >= 0:\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)})                    \n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "#         return self.weights, obj, epoch   \n",
    "       \n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "#         r =[]\n",
    "        \n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], l)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         t.append(s)        \n",
    "        \n",
    "#         return t,r, q\n",
    "        \n",
    "# #     def feedforward(self, data):\n",
    "# #         r =[]\n",
    "# #         prev = data\n",
    "        \n",
    "# #         r.append(prev)\n",
    "# #         t =[]\n",
    "\n",
    "# #         for j in range(self.nLayers):\n",
    "# #             l = []\n",
    "# #             s = []\n",
    "# #             for m in range(self.nNodes):\n",
    "# #                 #print(self.weights[j][\"weights\"][m])\n",
    "# #                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "# #             for k in s:\n",
    "# #                 l.append(af(k))\n",
    "# #             l.append(1)\n",
    "# #             prev = np.asarray(l)\n",
    "# #             t.append(s)\n",
    "# #             r.append(l)\n",
    "            \n",
    "# #         s =[]\n",
    "# #         p = np.matmul(self.weights[nLayers][\"weights\"][0], l)\n",
    "# #         s.append(p)\n",
    "# #         q = af(p)\n",
    "# #         t.append(s)        \n",
    "        \n",
    "# #         return t,r\n",
    "\n",
    "#     def backprop(self, d, data):\n",
    "#         der = []\n",
    "#         #t,r= self.feedforward(data)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         t,r,q = self.predict(data)\n",
    "        \n",
    "#         for i in range(self.nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(self.nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = []\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[nLayers][0]))\n",
    "#         diff.append(d - q)\n",
    "#         der.append(s)\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer = self.weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(self.weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(self.weights[i + 1]['weights'])):\n",
    "#                         error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff[0])\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "#         for j in range(len(self.weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "# import numpy as np\n",
    "\n",
    "# #np.random.seed(100)\n",
    "\n",
    "\n",
    "# # Sigmoid is the activation Function\n",
    "# def af(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def af_derivative(p):\n",
    "#     return af(p) * (1 -af(p))\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             #p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         y = af(y)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, ep = 0):\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         self.ep = ep\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "# #         newdata = []\n",
    "# #         for i in range(len(x)):\n",
    "# #             newdata.append(np.append(x[i],1))     \n",
    "# #         self.data = newdata\n",
    "#         self.data = x\n",
    "        \n",
    "        \n",
    "#         self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}] #create the weights from the inputs to the first layer\n",
    "#         for i in range(self.nLayers-1):\n",
    "#             self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers > 0:\n",
    "            \n",
    "#             self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes)}) #create weights from final layer to output node\n",
    "#         #return self.weights\n",
    "#         self.train()\n",
    " \n",
    "\n",
    "        \n",
    "#     def train(self):\n",
    "        \n",
    "\n",
    "#         #print(np.asarray(self.data))\n",
    "# #         print(self.labels)\n",
    "#         #temp_weights = self.weight_initialization()\n",
    "#         #print(self.weights)\n",
    "#         temp_eta = self.eta\n",
    "# #         temp2 = mse(self.data, self.labels, self.weights, self.nLayers, self.nNodes)\n",
    "# #         print(temp2)\n",
    "# #         print(f) \n",
    "#         e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "# #         epoch.append(e)\n",
    "# #         obj.append(temp2)\n",
    "#         cos = 100000000\n",
    "# #         #epd = 10000000\n",
    "#         while cos >= 0.1:\n",
    "#         #while cos >= 0.1:\n",
    "#             #print(cos)\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 #print(i)\n",
    "#                 self.backprop(self.labels[i], self.data[i]) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "\n",
    "#             cos = mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes)\n",
    "# #             epoch.append(e)\n",
    "# #             obj.append(cos)\n",
    "# #             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 cos = 100000000\n",
    "# #                 self.weights = temp_weights\n",
    "# #                 print(temp_weights)\n",
    "                \n",
    "#                 if self.eta <= 0.00001:                    \n",
    "#                     self.eta = temp_eta  \n",
    "# #                     obj =[]\n",
    "# #                     epoch = []\n",
    "# #                     e = 0\n",
    "# #                     cos = 100000000\n",
    "#                     self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}]\n",
    "#                     for i in range(self.nLayers-1):\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes)})\n",
    "#                     if self.nLayers >= 0:\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes)})                    \n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "#         #print(self.weights)\n",
    "#         return 0.0\n",
    "       \n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "# #         prev = np.append(x,1)\n",
    "#         r =[]\n",
    "        \n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             #l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         print(p)\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], l)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         t.append(s)\n",
    "#         #print(q)\n",
    "        \n",
    "#         return q\n",
    "#     def feedforward(self,x=[]):\n",
    "#         prev = x\n",
    "#         r =[]\n",
    "        \n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             #l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], l)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         t.append(s)        \n",
    "        \n",
    "#         return t,r\n",
    "        \n",
    "        \n",
    "#     def backprop(self, d, data):\n",
    "#         der = []\n",
    "#         #t,r= self.feedforward(data)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         t,r = self.feedforward(data)\n",
    "#         q = self.predict(data)\n",
    "        \n",
    "#         for i in range(self.nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(self.nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = []\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[nLayers][0]))\n",
    "#         diff.append(d - q)\n",
    "#         der.append(s)\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer = self.weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(self.weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(self.weights[i + 1]['weights'])):\n",
    "#                         error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff[0])\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "#         for j in range(len(self.weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "\n",
    "# import numpy as np\n",
    "# #np.random.seed(100)\n",
    "\n",
    "# # Sigmoid is the activation Function\n",
    "# def af(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def af_derivative(p):\n",
    "#     return af(p) * (1 -af(p))\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000):\n",
    "#         self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         #self.ep = ep\n",
    "#         #self.train()\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "#         self.data = newdata\n",
    "#         self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}] #create the weights from the inputs to the first layer\n",
    "#         for i in range(self.nLayers-1):\n",
    "#             self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers > 0:\n",
    "            \n",
    "#             self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)}) #create weights from final layer to output node\n",
    "#         #return self.weights\n",
    "        \n",
    "        \n",
    "#     def train(self):\n",
    "#         print(self.weights)\n",
    "#         temp_eta = self.eta\n",
    "#         temp_weights = self.weights\n",
    "#         temp2 = mse(self.data, self.labels, self.weights, self.nLayers, self.nNodes)\n",
    "#         print(temp2)\n",
    "#         e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "#         cos = 100000000\n",
    "#         while e < self.maxIt:\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 #print(self.data[i])\n",
    "#                 self.backprop(self.labels[i], self.data[i]) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "# #                 print(self.weights)\n",
    "# #                 print(f)\n",
    "\n",
    "\n",
    "\n",
    "#             cos = mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes)\n",
    "\n",
    "# #             epoch.append(e)\n",
    "# #             obj.append(cos)\n",
    "# #             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 if self.eta <= 0.00001:\n",
    "                    \n",
    "#                     self.eta = temp_eta  \n",
    "                    \n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 self.weights = temp_weights                \n",
    "#                 cos = 100000000\n",
    "\n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "\n",
    "#         #print(self.weights)\n",
    "#         return self.weights, obj, epoch   \n",
    "       \n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "        \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         #q = af(p)\n",
    "#         return p\n",
    "        \n",
    "#     def feedforward(self, data):\n",
    "#         r =[]\n",
    "#         prev = data\n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.dot(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         p = np.dot(self.weights[nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         t.append(s)        \n",
    "        \n",
    "#         return t,r\n",
    "\n",
    "#     def backprop(self, d, data):\n",
    "#         der = []\n",
    "#         t,r= self.feedforward(data)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         q = self.predict(data)\n",
    "        \n",
    "#         for i in range(self.nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(self.nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = d-q\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[nLayers][0]))\n",
    "#         der.append(s)\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer = self.weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(self.weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(self.weights[i + 1]['weights'])):\n",
    "#                         error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff)\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "#         for j in range(len(self.weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the _init_(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "\n",
    "# import numpy as np\n",
    "# np.random.seed(100)\n",
    "\n",
    "# def sigmoid(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def sigmoid_derivative(v):\n",
    "#     f_v = sigmoid(v)\n",
    "#     return f_v * (1 - f_v) * v\n",
    "\n",
    "# class NeuralNetwork:\n",
    "\n",
    "#     #Do not change this function header\n",
    "#     def _init_(self,x=[[]],y=[],numLayers=2,numNodes=2,eta=0.001,maxIter=10000):\n",
    "#         self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "\n",
    "#         # Other useful variables\n",
    "#         self.num_samples = len(self.data)\n",
    "#         self.num_features = len(self.data[0])\n",
    "\n",
    "#         # List for storing weights of each layer\n",
    "#         self.weights = list()\n",
    "#         # First hidden layer weights\n",
    "#         self.weights.append(self.get_weights(size=(self.num_features, self.nNodes)))\n",
    "#         # Other hidden layer weights\n",
    "#         for i in range(self.nLayers - 1):\n",
    "#             self.weights.append(self.get_weights(size=(self.nNodes, self.nNodes)))\n",
    "#         # Output layer weights\n",
    "#         self.weights.append(self.get_weights(size=(self.nNodes, 1)))\n",
    "\n",
    "#         self.train()\n",
    "\n",
    "#     def get_weights(self, size: tuple):\n",
    "#         # Drawing samples from LeCun normal distribution\n",
    "#         # Source: https://arxiv.org/pdf/1706.02515.pdf\n",
    "#         return np.random.normal(loc=0, scale=(1/size[0]), size=size)\n",
    "\n",
    "#     def train(self):\n",
    "#         for sample, label in zip(self.data, self.labels):\n",
    "#             sample = np.array(sample).reshape((self.num_features, 1))\n",
    "#             linear_activations, non_linear_activations = self.feedforward(sample)\n",
    "#             predicted = non_linear_activations[-1]\n",
    "#             initial_error = predicted - label\n",
    "#             layer_delta = self.backprop(linear_activations, initial_error)\n",
    "#             self.update_weights(sample, non_linear_activations, layer_delta)\n",
    "\n",
    "#     def update_weights(self, initial_input, non_linear_activations, layer_delta):\n",
    "#         current_input = initial_input\n",
    "#         for i in range(len(self.weights)):\n",
    "#             w_i = self.weights[i]\n",
    "#             update = self.eta * current_input.dot(layer_delta[i].T)\n",
    "#             self.weights[i] = w_i - update\n",
    "#             current_input = non_linear_activations.pop(0)\n",
    "\n",
    "#     def predict(self, x=[]):\n",
    "#         x = np.array(x).reshape((self.num_features, 1))\n",
    "#         return self.feedforward(x)[1][-1]\n",
    "\n",
    "#     def feedforward(self, x_i):\n",
    "#         current_input = x_i\n",
    "#         linear_activations = list()\n",
    "#         non_linear_activations = list()\n",
    "#         for weight in self.weights:\n",
    "#             z = weight.T.dot(current_input)\n",
    "#             a = sigmoid(z)\n",
    "#             linear_activations.append(z)\n",
    "#             non_linear_activations.append(a)\n",
    "#             current_input = a\n",
    "#         return linear_activations, non_linear_activations\n",
    "\n",
    "#     def backprop(self, linear_activations, initial_error):\n",
    "#         current_error = initial_error\n",
    "#         layer_delta = list()\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer_w = self.weights[i + 1] if i + 1 < len(self.weights) else np.array([[1]])\n",
    "#             delta = layer_w.dot(current_error) * sigmoid_derivative(linear_activations[i])\n",
    "#             layer_delta.insert(0, delta)\n",
    "#             current_error = delta\n",
    "#         return layer_delta\n",
    "\n",
    "\n",
    "# #if _name_ == '_main_':\n",
    "# x_data = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "# y_data = [0, 1, 1, 0]\n",
    "# nn_regressor = NeuralNetwork(x_data, y_data, maxIter=10000)\n",
    "# print(y_data)\n",
    "# print([nn_regressor.predict(x) for x in x_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The commented variables are suggestions so change them as appropriate,\n",
    "#However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "#You may create additional functions as you see fit\n",
    "\n",
    "import numpy as np\n",
    "#np.random.seed(100)\n",
    "\n",
    "\n",
    "# Sigmoid is the activation Function\n",
    "def af(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "def af_derivative(p):\n",
    "    return af(p) * (1 -af(p))\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "#np.random.seed(100)\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, ep = 0):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        self.nLayers = numLayers\n",
    "        self.nNodes = numNodes\n",
    "        self.numOutputs = numOutputs\n",
    "        self.eta = eta\n",
    "        self.maxIt = maxIter\n",
    "        self.ep = ep\n",
    "        #self.train()\n",
    "        #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "#         self.data = newdata\n",
    "        self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}] #create the weights from the inputs to the first layer\n",
    "        for i in range(self.nLayers-1):\n",
    "            self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes)}) #create the random weights between internal layers\n",
    "            \n",
    "        if self.nLayers > 0:\n",
    "            \n",
    "            self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes)}) #create weights from final layer to output node\n",
    "        #return self.weights\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "\n",
    "        print(self.data)\n",
    "        #temp_weights = self.weight_initialization()\n",
    "        print(self.weights)\n",
    "#         temp_eta = self.eta\n",
    "#         temp2 = mse(self.data, self.labels, self.weights, self.nLayers, self.nNodes)\n",
    "#         print(temp2)\n",
    "#         print(f) \n",
    "        e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "#         epoch.append(e)\n",
    "#         obj.append(temp2)\n",
    "#         cos = 100000000\n",
    "#         #epd = 10000000\n",
    "        while e < self.maxIt:\n",
    "            #print(cos)\n",
    "            #prev = cos\n",
    "            for i in range(len(self.data)):\n",
    "                #print(i)\n",
    "                self.backprop(self.labels[i], self.data[i]) \n",
    "                for m in range(len(self.weights)):\n",
    "                    for j in range(len(self.weights[m]['weights'])):\n",
    "                        for k in range(len(self.weights[m]['weights'][j])):\n",
    "                            self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "#                 print('\\n')\n",
    "#                 print(self.weights)\n",
    "#                 print(f)\n",
    "\n",
    "\n",
    "            #cos = mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes)\n",
    "            e += 1\n",
    "#             epoch.append(e)\n",
    "#             obj.append(cos)\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 if self.eta <= 0.00001:\n",
    "                    \n",
    "#                     self.eta = temp_eta  \n",
    "#                     #print(self.eta)\n",
    "                    \n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 epoch.append(e)\n",
    "#                 #print(temp_weights)\n",
    "#                 temp_mse = mse(self.data, self.labels, temp_weights, self.nLayers,self.nNodes)\n",
    "#                 obj.append(temp_mse)\n",
    "#                 #print(temp_mse)                \n",
    "#                 cos = 100000000\n",
    "#                 #epd = 100000000\n",
    "\n",
    "#             elif cos <= prev:\n",
    "#                 e += 1\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 #epd = abs(cos - prev)\n",
    "#                 #print(g)\n",
    "        #print(self.weights)\n",
    "        return self.weights   \n",
    "       \n",
    "\n",
    "    def predict(self,x=[]):\n",
    "        prev = x\n",
    "        for j in range(self.nLayers):\n",
    "            l = []\n",
    "            s = []\n",
    "            for m in range(self.nNodes):\n",
    "                s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "            for k in s:\n",
    "                l.append(af(k))\n",
    "            #l.append(1)\n",
    "            prev = np.asarray(l)\n",
    "        \n",
    "        s =[]\n",
    "        p = np.matmul(self.weights[self.nLayers][\"weights\"][0], prev)\n",
    "        s.append(p)\n",
    "        q = af(p)\n",
    "        return q\n",
    "        \n",
    "    def feedforward(self, data):\n",
    "        r =[]\n",
    "        prev = data\n",
    "        r.append(prev)\n",
    "        t =[]\n",
    "\n",
    "        for j in range(self.nLayers):\n",
    "            l = []\n",
    "            s = []\n",
    "            for m in range(self.nNodes):\n",
    "                #print(self.weights[j][\"weights\"][m])\n",
    "                s.append(np.dot(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "            for k in s:\n",
    "                l.append(af(k))\n",
    "            #l.append(1)\n",
    "            prev = np.asarray(l)\n",
    "            t.append(s)\n",
    "            r.append(l)\n",
    "            \n",
    "        s =[]\n",
    "        p = np.dot(self.weights[nLayers][\"weights\"][0], l)\n",
    "        s.append(p)\n",
    "        q = af(p)\n",
    "        t.append(s)        \n",
    "        \n",
    "        return t,r\n",
    "\n",
    "    def backprop(self, d, data):\n",
    "        der = []\n",
    "        t,r= self.feedforward(data)\n",
    "#         print('\\n')\n",
    "#         print(\"t = \" + str(t))\n",
    "#         print('\\n')\n",
    "#         print('r = ' + str(r))  \n",
    "        q = self.predict(data)\n",
    "        \n",
    "        for i in range(self.nLayers):\n",
    "            a =[]\n",
    "            for m in range(self.nNodes):\n",
    "                a.append(af_derivative(t[i][m]))\n",
    "            der.append(a)\n",
    "        \n",
    "        diff = []\n",
    "        s =[]\n",
    "        s.append(af_derivative(t[nLayers][0]))\n",
    "        diff.append(d - q)\n",
    "        der.append(s)\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            layer = self.weights[i]\n",
    "            errors = []\n",
    "            if i != len(self.weights)-1:\n",
    "                for j in range(len(layer['weights'])):\n",
    "                    error = 0\n",
    "                    \n",
    "                    for k in range(len(self.weights[i + 1]['weights'])):\n",
    "                        error = (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "                    errors.append(error)\n",
    "            else:\n",
    "                errors.append(diff[0])\n",
    "            layer['s'] = []\n",
    "            for j in range(len(layer['weights'])):\n",
    "                layer['s'].append(errors[j]*der[i][j])\n",
    "#         print('\\n')\n",
    "        #print(weights)\n",
    "        #print(f)\n",
    "        for j in range(len(self.weights)):\n",
    "            layer = self.weights[j]\n",
    "            layer['g'] = []\n",
    "            for k in range(len(self.weights[j]['weights'])):\n",
    "                s =[]\n",
    "                for m in range(len(self.weights[j]['weights'][k])):\n",
    "                    s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "                layer['g'].append(s)\n",
    "\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "\n",
    "# import numpy as np\n",
    "# #np.random.seed(100)\n",
    "\n",
    "# def sigmoid(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def sigmoid_derivative(p):\n",
    "#     return sigmoid(p) * (1 -sigmoid(p))\n",
    "\n",
    "# class NeuralNetwork:\n",
    "\n",
    "#     #Do not change this function header\n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000):\n",
    "#         self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         self.weights = [{\"weights\":np.random.rand(numNodes, len(x[0]))}] #create the weights from the inputs to the first layer\n",
    "       \n",
    "#         for i in range(self.nLayers-1):\n",
    "#             self.weights.append({\"weights\":np.random.rand(numNodes,numNodes)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers > 0:           \n",
    "#             self.weights.append({\"weights\":np.random.rand(numOutputs,numNodes)}) #create weights from final layer to output node\n",
    "#         self.outputs = np.zeros(y.shape)\n",
    "\n",
    "                \n",
    "#     def train(self):\n",
    "#         np.random.shuffle(self.data)\n",
    "#         print(self.weights)\n",
    "#         for e in  range(self.maxIt):           \n",
    "#             for i in range(len(self.data)):\n",
    "#                 self.backprop(self.labels[i], self.data[i], self.weights, self.nLayers, self.nNodes) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] += (self.eta * self.weights[m]['g'][j][k])\n",
    "#                 print('\\n')\n",
    "#                 print(self.weights)\n",
    "#                 print(f)\n",
    "#         return self.weights\n",
    "\n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "#             for k in s:\n",
    "#                 l.append(sigmoid(k))\n",
    "#             prev = np.asarray(l)\n",
    "        \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         q = sigmoid(p)\n",
    "#         return q\n",
    "\n",
    "#     def feedforward(self, data, weights, nLayers, nNodes):\n",
    "#         r =[]\n",
    "#         prev = data\n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "#         for j in range(nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(nNodes):\n",
    "#                 s.append(np.dot(weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(sigmoid(k))\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "        \n",
    "#         s =[]\n",
    "#         p = np.dot(weights[nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         #p = sigmoid(p)\n",
    "#         t.append(s)              \n",
    "#         return t,r\n",
    "\n",
    "#     def backprop(self, d, data, weights, nLayers, nNodes):\n",
    "#         der = []\n",
    "#         t,r = self.feedforward(data, weights, nLayers, nNodes) \n",
    "#         print('\\n')\n",
    "#         print(\"t = \" + str(t))\n",
    "#         print('\\n')\n",
    "#         print('r = ' + str(r))\n",
    "#         q = self.predict(data)\n",
    "#         for i in range(nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(nNodes):\n",
    "#                 a.append(sigmoid_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = d-q\n",
    "#         s =[]\n",
    "#         s.append(sigmoid_derivative(t[nLayers][0]))\n",
    "#         der.append(s)\n",
    "#         print(der)\n",
    "#         print(diff)\n",
    "#         for i in reversed(range(len(weights))):\n",
    "#             layer = weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0                    \n",
    "#                     for k in range(len(weights[i + 1]['weights'])):\n",
    "#                         error += (weights[i + 1]['weights'][k][j] * weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff)             \n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "#         print(self.weights)\n",
    "       \n",
    "#         for j in range(len(weights)):\n",
    "#             layer = weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(layer['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(layer['weights'][k])):\n",
    "#                     #print(self.weights[j]['s'][k])\n",
    "#                     s.append((((r[j][m])*layer['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "#         print('\\n')\n",
    "#         print('G')\n",
    "#         print(self.weights)\n",
    "#         return 0.0\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
