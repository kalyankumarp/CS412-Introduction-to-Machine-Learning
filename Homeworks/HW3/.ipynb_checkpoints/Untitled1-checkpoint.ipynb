{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5],\n",
       "       [0.5, 1.5, 0.5],\n",
       "       [1.5, 0.5, 0.5],\n",
       "       [1.5, 1.5, 0.5]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =[[0.5,0.5, 0.5],[0.5,1.5, 0.5],[1.5,0.5, 0.5],[1.5,1.5, 0.5]]\n",
    "y=[0,1,1,0]\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "\n",
    "# import numpy as np\n",
    "# #np.random.seed(100)\n",
    "\n",
    "\n",
    "# # Sigmoid is the activation Function\n",
    "# def af(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def af_derivative(p):\n",
    "#     return af(p) * (1 -af(p))\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, ep = 0):\n",
    "#         #self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         self.ep = ep\n",
    "#         #self.train()\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "#         self.data = newdata\n",
    "#         self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}] #create the weights from the inputs to the first layer\n",
    "#         for i in range(self.nLayers):\n",
    "#             self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers > 0:\n",
    "            \n",
    "#             self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)}) #create weights from final layer to output node\n",
    "#         #return self.weights\n",
    "        \n",
    "        \n",
    "#     def train(self):\n",
    "        \n",
    "\n",
    "#         print(self.data)\n",
    "# #         #temp_weights = self.weight_initialization()\n",
    "# #         print(self.weights)\n",
    "#         temp_eta = self.eta\n",
    "# #         temp2 = mse(self.data, self.labels, self.weights, self.nLayers + 1, self.nNodes)\n",
    "# #         print(temp2)\n",
    "# #         print(f) \n",
    "#         e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "\n",
    "#         cos = 100000000\n",
    "# #         #epd = 10000000\n",
    "#         while cos >= 0.05:\n",
    "#             #print(cos)\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 #print(i)\n",
    "#                 self.backprop(self.labels[i], self.data[i]) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "# #                 print('\\n')\n",
    "# #                 print(self.weights)\n",
    "# #                 print(f)\n",
    "\n",
    "\n",
    "#             cos = mse(self.data, self.labels, self.weights, self.nLayers + 1,self.nNodes)\n",
    "# #             epoch.append(e)\n",
    "# #             obj.append(cos)\n",
    "# #             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 cos = 100000000\n",
    "# #                 self.weights = temp_weights\n",
    "# #                 print(temp_weights)\n",
    "                \n",
    "#                 if self.eta <= 0.00001:                    \n",
    "#                     self.eta = temp_eta  \n",
    "# #                     obj =[]\n",
    "# #                     epoch = []\n",
    "# #                     e = 0\n",
    "# #                     cos = 100000000\n",
    "#                     self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}]\n",
    "#                     for i in range(self.nLayers):\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)})\n",
    "#                     if self.nLayers >= 0:\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)})                    \n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "#                 #print(g)\n",
    "#         #print(self.weights)\n",
    "#         return self.weights   \n",
    "       \n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "        \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers + 1][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         return q\n",
    "        \n",
    "#     def feedforward(self, data):\n",
    "#         r =[]\n",
    "#         prev = data\n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.dot(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         p = np.dot(self.weights[self.nLayers + 1][\"weights\"][0], l)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         t.append(s)        \n",
    "        \n",
    "#         return t,r, q\n",
    "\n",
    "#     def backprop(self, d, data):\n",
    "#         der = []\n",
    "#         t,r, q= self.feedforward(data)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         #q = self.predict(data)\n",
    "        \n",
    "#         for i in range(self.nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(self.nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = []\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[self.nLayers][0]))\n",
    "#         diff.append(d - q)\n",
    "#         der.append(s)\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer = self.weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(self.weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(self.weights[i + 1]['weights'])):\n",
    "#                         error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff[0])\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "# #         print('\\n')\n",
    "#         #print(weights)\n",
    "#         #print(f)\n",
    "#         for j in range(len(self.weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# np.random.seed(100)\n",
    "\n",
    "\n",
    "# # Rectified linear Unit Activation Function\n",
    "# def af(t):\n",
    "#     if t >= 0: \n",
    "#         return t\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# # Its derivative\n",
    "# def af_derivative(p):\n",
    "#     if p >= 0:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# Sigmoid is the activation Function\n",
    "def af(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "def af_derivative(p):\n",
    "    return af(p) * (1 -af(p))\n",
    "\n",
    "def decision(x):\n",
    "    if x >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def mse_misclassifications(x, d, w, nLayers, nNodes):\n",
    "    c = 0\n",
    "    count = 0\n",
    "    n = len(x)\n",
    "    for i in range(0,n):\n",
    "        prev = x[i]             \n",
    "        for j in range(nLayers):\n",
    "            u =[]\n",
    "            p =[]\n",
    "            for k in range(nNodes):\n",
    "                t = np.dot(w[j]['weights'][k], prev)\n",
    "                u.append(t)\n",
    "            for l in u:\n",
    "                p.append(af(l))\n",
    "            #p.append(1)\n",
    "            prev = np.asarray(p)\n",
    "        #print(w[nLayers][\"weights\"][0])\n",
    "        y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "        if np.any(d[i] - y):\n",
    "            count += 1\n",
    "        c += np.linalg.norm(d[i] - y)**2           \n",
    "    return c/n, count\n",
    "\n",
    "\n",
    "\n",
    "#np.random.seed(100)\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, prec = 0):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        self.nLayers = numLayers\n",
    "        self.nNodes = numNodes\n",
    "        self.numOutputs = numOutputs\n",
    "        self.eta = eta\n",
    "        self.temp_eta = eta\n",
    "        self.maxIt = maxIter\n",
    "        self.prec = prec\n",
    "        #self.train()\n",
    "        #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "#         self.data = newdata\n",
    "        self.weights = [{\"weights\":np.random.uniform(low =-1, high = 1, size = (self.nNodes, len(self.data[0])))}] \n",
    "        for i in range(self.nLayers):\n",
    "            self.weights.append({\"weights\":np.random.uniform(low =-1, high = 1, size = (self.nNodes,self.nNodes))})             \n",
    "        if self.nLayers >= 0:            \n",
    "            self.weights.append({\"weights\":np.random.uniform(low =-1, high = 1, size = (self.numOutputs,self.nNodes))})\n",
    "        self.temp_weights = self.weights\n",
    "         \n",
    "        \n",
    "    def train(self):\n",
    "        np.random.shuffle(self.data)\n",
    "        print('K')\n",
    "        print(self.data[0])\n",
    "        print(self.weights)\n",
    "        #print(self.weights[0]['weights'][0])\n",
    "        \n",
    "        temp_weights = self.weights\n",
    "        temp_eta = self.temp_eta\n",
    "        temp2, temp3 = mse_misclassifications(self.data, self.labels, self.weights, self.nLayers + 1, self.nNodes)\n",
    "#         print(temp2)\n",
    "#         print(temp3)\n",
    "#         print(f)\n",
    "        e = 0\n",
    "        obj =[]\n",
    "        epoch = []\n",
    "        mis = []\n",
    "        obj.append(temp2)\n",
    "        mis.append(temp3)\n",
    "        cos = 100000000\n",
    "#         while e < self.maxIt:\n",
    "#             #print(\"K\")\n",
    "        while e <= self.maxIt:\n",
    "            e += 1\n",
    "            prev = cos\n",
    "            np.random.shuffle(self.data)\n",
    "            i = 0\n",
    "            while i < len(self.data):\n",
    "                #print(i)\n",
    "                #print(len(self.data[i]))\n",
    "                self.backprop(self.labels[i], self.data[i]) \n",
    "                print(self.weights)\n",
    "                print(f)\n",
    "                for m in range(len(self.weights)):\n",
    "                    for j in range(len(self.weights[m]['weights'])):\n",
    "                        for k in range(len(self.weights[m]['weights'][j])):\n",
    "                            self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "                \n",
    "                i += 1\n",
    "#             print(self.weights)\n",
    "#             print(f)\n",
    "\n",
    "            cos, misc = mse_misclassifications(self.data, self.labels, self.weights, self.nLayers + 1,self.nNodes)            \n",
    "            epoch.append(e)\n",
    "            obj.append(cos)\n",
    "            mis.append(misc)\n",
    "#             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 cos = 100000000\n",
    "# #                 self.weights = temp_weights\n",
    "# #                 print(temp_weights)\n",
    "                \n",
    "#                 if self.eta <= 0.00001:                    \n",
    "#                     self.eta = temp_eta  \n",
    "# #                     obj =[]\n",
    "# #                     epoch = []\n",
    "# #                     e = 0\n",
    "# #                     cos = 100000000\n",
    "#                     self.weights = [{\"weights\":np.random.uniform(low =-1, high = 1, size = (self.nNodes, len(self.data[0])))}] \n",
    "#                     for i in range(self.nLayers):\n",
    "#                         self.weights.append({\"weights\":np.random.uniform(low =-1, high = 1, size = (self.nNodes,self.nNodes+1))})             \n",
    "#                     if self.nLayers >= 0:            \n",
    "#                         self.weights.append({\"weights\":np.random.uniform(low =-1, high = 1, size = (self.numOutputs,self.nNodes+1))})\n",
    "                     \n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "#                 #print(g)\n",
    "        print(self.weights)\n",
    "        return self.weights, obj, epoch, mis   \n",
    "       \n",
    "\n",
    "    def feedforward(self,x=[]):\n",
    "        #print(x)\n",
    "        prev = x\n",
    "        r =[]      \n",
    "        r.append(prev)\n",
    "        t =[]\n",
    "        for j in range(self.nLayers + 1):\n",
    "            l = []\n",
    "            s = []\n",
    "            for m in range(self.nNodes):\n",
    "                #print(self.weights[j][\"weights\"][m])\n",
    "                s.append(np.matmul(self.weights[j][\"weights\"][m], prev)) \n",
    "            for k in s:\n",
    "                l.append(af(k))\n",
    "            #l.append(1)\n",
    "            prev = np.asarray(l)\n",
    "            t.append(s)\n",
    "            r.append(l)\n",
    "            \n",
    "        s =[]\n",
    "        for i in range(self.numOutputs):\n",
    "            \n",
    "            p = np.matmul(self.weights[self.nLayers + 1][\"weights\"][i], l)\n",
    "            s.append(af(p))\n",
    "        t.append(s)              \n",
    "        return t,r        \n",
    "\n",
    "    def backprop(self, d, data):\n",
    "        der = []  \n",
    "        \n",
    "        t,r = self.feedforward(data)\n",
    "#         print('\\n')\n",
    "#         print(\"t = \" + str(t))\n",
    "#         print('\\n')\n",
    "#         print('r = ' + str(r))\n",
    "        \n",
    "        for i in range(self.nLayers + 1):\n",
    "            a =[]\n",
    "            for m in range(self.nNodes):\n",
    "                a.append(af_derivative(t[i][m]))\n",
    "            der.append(a)\n",
    "        diff = d - t[self.nLayers + 1]\n",
    "\n",
    "        s =[]\n",
    "        for k in range(self.numOutputs):\n",
    "            s.append(af_derivative(t[self.nLayers + 1][k]))\n",
    "\n",
    "        der.append(s)\n",
    "    \n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            layer = self.weights[i]\n",
    "            errors = []\n",
    "            if i != len(self.weights)-1:\n",
    "                for j in range(len(layer['weights'])):\n",
    "                    error = 0\n",
    "                    \n",
    "                    for k in range(len(self.weights[i + 1]['weights'])):\n",
    "                        error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "                    errors.append(error)\n",
    "                layer['s'] = []\n",
    "                for j in range(len(layer['weights'])):\n",
    "                    layer['s'].append(errors[j]*der[i][j])\n",
    "            else:\n",
    "                errors.append(diff)\n",
    "\n",
    "                layer['s'] = []\n",
    "                for j in range(len(layer['weights'])):\n",
    "                    layer['s'].append(errors[0][j]*der[i][j])\n",
    "\n",
    "\n",
    "\n",
    "# Finding the corresponding gradient vector\n",
    "                \n",
    "        for j in range(len(self.weights)):\n",
    "            layer = self.weights[j]\n",
    "            layer['g'] = []\n",
    "            for k in range(len(self.weights[j]['weights'])):\n",
    "                s =[]\n",
    "                for m in range(len(self.weights[j]['weights'][k])):\n",
    "                    s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "                layer['g'].append(s)\n",
    "\n",
    "        return 0.0\n",
    "\n",
    "class Neural_Network():\n",
    "    \n",
    "    def __init__(self, x=[[]], y=[], nHiddenLayers = 0, nHiddenNodes =0, numOutputs = 0, eta = 1, iter = 0, prec = 0):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        self.nInputNodes = x.shape[1]\n",
    "        self.nHiddenLayers = nHiddenLayers\n",
    "        self.nHiddenNodes = nHiddenNodes\n",
    "        self.numOutputs = numOutputs\n",
    "        self.eta = eta\n",
    "        self.maxIt = iter\n",
    "        self.prec = prec\n",
    "\n",
    "        self.weights=[np.random.uniform(low = -1, high = 1, size = (self.nHiddenNodes, self.nInputNodes))]\n",
    "        for i in range(self.nHiddenLayers-1):\n",
    "            self.weights.append(np.random.uniform(low =-1, high = 1, size =(self.nHiddenNodes, self.nHiddenNodes))) \n",
    "        self.weights.append(np.random.uniform(low =-1, high = 1, size = (self.numOutputs, self.nHiddenNodes)))\n",
    "\n",
    "        # Sigmoid activation function\n",
    "\n",
    "    def sigmoid(self, s):      \n",
    "        return 1/(1+np.exp(-s))\n",
    "\n",
    "    #derivative of sigmoid\n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def af(self,s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "    \n",
    "    def af_derivative(self,s):\n",
    "        return s * (1 - s)\n",
    "        \n",
    "    \n",
    "#     def decision_A(self,x):\n",
    "#         out =[]\n",
    "# #         print(x.shape)\n",
    "# #         print(f)\n",
    "#         for i in range(x.shape[0]):\n",
    "#             s =np.zeros(x.shape[1])\n",
    "            \n",
    "            \n",
    "#             max = np.argmax(x[i])\n",
    "#             #print(max)\n",
    "\n",
    "#             s[max] = 1\n",
    "#             out.append(s)\n",
    "#         out = np.asarray(out)\n",
    "#         print(out.shape)\n",
    "#         print(f)\n",
    "#         return out\n",
    "\n",
    "    def misclassifications(self, x,y):\n",
    "        count = 0\n",
    "        for i in range(y.shape[0]): \n",
    "            if np.any(x[i]-y[i]):\n",
    "                count += 1\n",
    "                \n",
    "        return count\n",
    "    \n",
    "    def predict(self):\n",
    "        prev = self.data.T\n",
    "#         print(prev)\n",
    "#         print(f)\n",
    "        for i in range(len(self.weights)-1):\n",
    "#             print(prev)\n",
    "#             print(self.weights[i])\n",
    "            temp = (np.matmul(self.weights[i], prev))\n",
    "#             print(temp)\n",
    "#             print(f)\n",
    "            temp2 = self.sigmoid(temp)\n",
    "#             print(temp2)\n",
    "#             print('\\n')\n",
    "            prev = temp2\n",
    "\n",
    "#         print(prev)\n",
    "#         print(self.weights[self.nHiddenLayers])\n",
    "        temp_f = np.matmul(self.weights[self.nHiddenLayers], prev)\n",
    "#         print(temp_f)\n",
    "        temp4 = self.af(np.transpose(temp_f)) \n",
    "#         print(temp4)\n",
    "#         print(f)\n",
    "        return temp4[:,0]\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "#         print(x)\n",
    "        self.r = []\n",
    "        self.r.append(x)\n",
    "#         print(self.r[0])\n",
    "#         print(f)\n",
    "        prev = x.T\n",
    "        \n",
    "        for i in range(len(self.weights)-1):\n",
    "#             print(self.weights[i])\n",
    "#             print(prev)\n",
    "            temp = np.matmul(self.weights[i], prev)\n",
    "#             print(temp)\n",
    "            temp2 = self.sigmoid(temp)\n",
    "#             print(temp2)\n",
    "            self.r.append(temp2)\n",
    "#             print(self.r)\n",
    "#             print('\\n')\n",
    "            prev = temp2\n",
    "            \n",
    "#         print(self.weights[self.nHiddenLayers])\n",
    "#         print(prev)\n",
    "        temp_f = np.matmul(self.weights[self.nHiddenLayers], prev)\n",
    "#         print(temp_f)\n",
    "\n",
    "        temp4 =self.af(temp_f.T)\n",
    "#         print(temp4[0][0])\n",
    "#         print(f)\n",
    "        return temp4[0][0]\n",
    "\n",
    "    def backward(self, x, y):\n",
    "        self.delta = []\n",
    "#         print(x)\n",
    "#         print(y)\n",
    "#         print(f)\n",
    "        o = self.feedforward(x)\n",
    "#         print('b')\n",
    "#         print(o)\n",
    "\n",
    "        self.out_error = y - o\n",
    "#         print(self.out_error)\n",
    "\n",
    "\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            if i == 0 and i != len(self.weights)-1:\n",
    "#                 print(temp)\n",
    "#                 print(self.weights[i+1].T)\n",
    "                temp2 = self.weights[i+1].T.dot(temp)\n",
    "#                 print(temp2)\n",
    "#                 print(self.r[i+1])\n",
    "#                 print(self.sigmoidPrime(self.r[i+1]))\n",
    "                temp3 = temp2*self.sigmoidPrime(self.r[i+1])\n",
    "#                 print(temp3)\n",
    "#                 print(x)\n",
    "                temp4 = (temp3.dot(x))*2/len(self.data)\n",
    "#                 print(temp4)\n",
    "#                 print('w')\n",
    "#                 print(self.weights[i])\n",
    "#                 print((self.eta*temp4*2)/len(self.data))\n",
    "                self.weights[i] += self.eta*temp4\n",
    "#                 print(self.weights[i])\n",
    "                temp = temp3\n",
    "                self.delta.append(temp4)\n",
    "                    \n",
    "            elif i > 0 and i<len(self.weights)-1:\n",
    "                temp2 = self.weights[i+1].T.dot(temp) \n",
    "                temp3 = temp2*self.sigmoidPrime(self.r[i+1])\n",
    "                temp4 = (temp3.dot(self.r[i].T))*2/len(self.data)\n",
    "                temp = temp3\n",
    "                self.delta.append(temp4)\n",
    "                self.weights[i] += self.eta*temp4\n",
    "                    \n",
    "            elif i == len(self.weights)-1:\n",
    "                temp = self.out_error*self.af_derivative(o)\n",
    "\n",
    "#                 print(self.weights[i])\n",
    "#                 print(temp)\n",
    "#                 print(self.r[i].T)\n",
    "                temp2 = (temp*self.r[i].T)*2/len(self.data)\n",
    "                self.delta.append(temp2)\n",
    "#                 print(temp2)\n",
    "#                 print((self.eta*temp2*2)/len(self.data))\n",
    "                self.weights[i] += self.eta*temp2\n",
    "#                 print(self.weights[i])\n",
    "#                 print('\\n')\n",
    "\n",
    "            \n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "    def train (self):\n",
    "        #print(self.eta)\n",
    "        print(self.weights)\n",
    "        e = 0\n",
    "        obj =[]\n",
    "        epoch = []\n",
    "        mis = []\n",
    "        epoch.append(e)\n",
    "        pred = self.predict()\n",
    "#         print(pred)\n",
    "# #         print(f)\n",
    "#         print(self.labels)\n",
    "#         print(np.linalg.norm(self.labels - pred)**2/4)\n",
    "        obj.append(((np.linalg.norm(self.labels - pred))**2)/len(self.data))\n",
    "#         print(obj)\n",
    "#         print(f)\n",
    "        mis.append(self.misclassifications(self.labels, pred))\n",
    "#         print(mis)\n",
    "#         print(f)\n",
    "        mse = 100000000000\n",
    "        while e <= 1: \n",
    "            prev = mse\n",
    "#             print(prev)\n",
    "#             print(f)\n",
    "            e += 1\n",
    "            for i in range(len(self.data)):                \n",
    "                self.backward(self.data[i].reshape(1,self.nInputNodes), self.labels[i])\n",
    "                print(self.delta)\n",
    "                print(f)\n",
    "#             print(self.weights)\n",
    "#             print(f)\n",
    "                \n",
    "#             print('after')\n",
    "#             print(self.weights)\n",
    "            pred = self.predict()\n",
    "#             print(pred)\n",
    "#             print(obj)\n",
    "            mse = ((np.linalg.norm(self.labels - pred))**2)/len(self.data)\n",
    "#             print(mse)\n",
    "#             print(f)\n",
    "\n",
    "            \n",
    "            obj.append(mse)\n",
    "            epoch.append(e)\n",
    "            mis.append(self.misclassifications(self.labels, pred))\n",
    "            if mse >= prev:\n",
    "                self.eta = 0.8*self.eta\n",
    "            prev = mse\n",
    "        print(self.weights)\n",
    "        return self.weights, epoch, obj, mis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.47741936, -0.33927319,  0.35173215],\n",
      "       [ 0.54074883, -0.45314883, -0.03114213]]), array([[0.57717016, 0.19000382]])]\n",
      "[array([[-0.02321695, -0.04497485]]), array([[-0.01293272, -0.00431091, -0.00431091],\n",
      "       [-0.00353664, -0.00117888, -0.00117888]])]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-cfea64d7fb32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeural_Network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnHiddenLayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnHiddenNodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumOutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-1f781ceb4113>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    447\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnInputNodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;31m#             print(self.weights)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;31m#             print(f)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "nHiddenLayers = 1\n",
    "nHiddenNodes =2\n",
    "numOutputs = 1\n",
    "eta = 1\n",
    "iter = 10000\n",
    "prec = 0.5\n",
    "#print(xtrain.shape)\n",
    "NN = Neural_Network(x, y, nHiddenLayers, nHiddenNodes, numOutputs, eta, iter, prec)\n",
    "\n",
    "w, epoch, obj, mis = NN.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K\n",
      "[1.5 1.5 0.5]\n",
      "[{'weights': array([[-0.55795119, -0.59664924,  0.56573597],\n",
      "       [ 0.10911626, -0.9071209 ,  0.51521003]])}, {'weights': array([[-0.41282954,  0.5310811 ]])}]\n",
      "[{'weights': array([[-0.55795119, -0.59664924,  0.56573597],\n",
      "       [ 0.10911626, -0.9071209 ,  0.51521003]]), 's': [0.007700083756651429, -0.012996873847461869], 'g': [[-0.005775062817488572, -0.005775062817488572, -0.0019250209391628572], [0.009747655385596401, 0.009747655385596401, 0.003249218461865467]]}, {'weights': array([[-0.41282954,  0.5310811 ]]), 's': [-0.12112196911782806], 'g': [[0.011515700557407239, 0.017018918342708755]]}]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-ce71623605a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnLayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnNodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnOut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-1f781ceb4113>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "nLayers = 0\n",
    "nNodes = 2\n",
    "nOut = 1\n",
    "eta = 1\n",
    "iter = 10000\n",
    "prec = 0.05\n",
    "\n",
    "w, obj, epoch, mis = NeuralNetwork(x,y, nLayers, nNodes, nOut, eta, iter, prec).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4977565530314928"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata = []\n",
    "for i in range(len(x)):\n",
    "    newdata.append(np.append(x[i],1))     \n",
    "cos, mis = mse_misclassifications(newdata, y, w, 1,2)\n",
    "cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,w):\n",
    "        #Do not change this function header\n",
    "        #print('\\n')\n",
    "        #print(\"Predict Function\")\n",
    "#     newdata = []\n",
    "#     for i in range(len(x)):\n",
    "#         newdata.append(np.append(x[i],1))\n",
    "#     newdata = np.asarray(newdata)\n",
    "    prev = np.append(x,1)\n",
    "    for j in range(nLayers):\n",
    "        #print(prev)\n",
    "        l = []\n",
    "        s = []\n",
    "        for m in range(nNodes):\n",
    "            #print(w[j][\"weights\"][m])\n",
    "            s.append(np.matmul(w[j][\"weights\"][m], prev))\n",
    "        for k in s:\n",
    "            l.append(af(k))\n",
    "        l.append(1)\n",
    "        prev = np.asarray(l)\n",
    "    s =[]\n",
    "    for n in range(nOut):\n",
    "\n",
    "        p = np.dot(prev,w[nLayers][\"weights\"][n])\n",
    "        s.append(p)\n",
    "    q = []\n",
    "    for i in range(len(s)):\n",
    "        q.append(af(s[i]))\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10566471984298263]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p= predict([0.5,0.5, 0.5], w)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5219109581721073"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af(0.0877)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24963934723851425"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af_derivative(0.076)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15617815132940527,\n",
       " 0.39930187620131075,\n",
       " 0.41335189442217146,\n",
       " 0.6881133459690951,\n",
       " 0.41195037138254215,\n",
       " 0.8430785393983047,\n",
       " 0.8361466071009599,\n",
       " 0.048627368891770384,\n",
       " 0.16861064580142782,\n",
       " 0.8434798365239617,\n",
       " -0.12957839763614887]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights =[]\n",
    "for j in range(len(w)):\n",
    "    for k in range(len(w[j]['weights'])):\n",
    "        for m in range(len(w[j]['weights'][k])):\n",
    "            weights.append(w[j]['weights'][k][m])\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6527358278270062],\n",
       " [0.678587063732908],\n",
       " [0.6668809008516015],\n",
       " [0.6864532238463801]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata = []\n",
    "for i in range(len(x)):\n",
    "    newdata.append(np.append(x[i],1))\n",
    "p = []\n",
    "for i in newdata:\n",
    "    p.append(predict(i,w))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 5, 14]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.transpose(np.mat([[0,1,2],[3,4,5]]))\n",
    "print(a.shape)\n",
    "b = np.mat([0,1,2])\n",
    "print(b.shape)\n",
    "np.matmul(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(numpy.array([1,3,4]) < numpy.array([4,6,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "\n",
    "\n",
    "# np.random.seed(100)\n",
    "\n",
    "\n",
    "# # Sigmoid is the activation Function\n",
    "# def af(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def af_derivative(p):\n",
    "#     return af(p) * (1 -af(p))\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         y = af(y)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, ep = 0):\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         self.ep = ep\n",
    "#         #self.train()\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "#         self.data = newdata\n",
    "#         self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}] #create the weights from the inputs to the first layer\n",
    "#         for i in range(self.nLayers-1):\n",
    "#             self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers > 0:\n",
    "            \n",
    "#             self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)}) #create weights from final layer to output node\n",
    "#         #return self.weights\n",
    "        \n",
    "        \n",
    "#     def train(self):\n",
    "        \n",
    "\n",
    "#         print(self.data)\n",
    "#         #temp_weights = self.weight_initialization()\n",
    "#         print(self.weights)\n",
    "#         temp_eta = self.eta\n",
    "#         temp2 = mse(self.data, self.labels, self.weights, self.nLayers, self.nNodes)\n",
    "#         print(temp2)\n",
    "# #         print(f) \n",
    "#         e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "# #         epoch.append(e)\n",
    "# #         obj.append(temp2)\n",
    "#         cos = 100000000\n",
    "# #         #epd = 10000000\n",
    "# #         while e < self.maxIt:\n",
    "#         while cos >= 0.1:\n",
    "#             #print(cos)\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 #print(i)\n",
    "#                 self.backprop(self.labels[i], self.data[i]) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "\n",
    "#             cos = mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes)\n",
    "# #             epoch.append(e)\n",
    "# #             obj.append(cos)\n",
    "# #             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 cos = 100000000\n",
    "# #                 self.weights = temp_weights\n",
    "# #                 print(temp_weights)\n",
    "                \n",
    "#                 if self.eta <= 0.00001:                    \n",
    "#                     self.eta = temp_eta  \n",
    "# #                     obj =[]\n",
    "# #                     epoch = []\n",
    "# #                     e = 0\n",
    "# #                     cos = 100000000\n",
    "#                     self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}]\n",
    "#                     for i in range(self.nLayers-1):\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)})\n",
    "#                     if self.nLayers >= 0:\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)})                    \n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "#         return self.weights, obj, epoch   \n",
    "       \n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "#         r =[]\n",
    "        \n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], l)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         t.append(s)        \n",
    "        \n",
    "#         return t,r, q\n",
    "        \n",
    "# #     def feedforward(self, data):\n",
    "# #         r =[]\n",
    "# #         prev = data\n",
    "        \n",
    "# #         r.append(prev)\n",
    "# #         t =[]\n",
    "\n",
    "# #         for j in range(self.nLayers):\n",
    "# #             l = []\n",
    "# #             s = []\n",
    "# #             for m in range(self.nNodes):\n",
    "# #                 #print(self.weights[j][\"weights\"][m])\n",
    "# #                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "# #             for k in s:\n",
    "# #                 l.append(af(k))\n",
    "# #             l.append(1)\n",
    "# #             prev = np.asarray(l)\n",
    "# #             t.append(s)\n",
    "# #             r.append(l)\n",
    "            \n",
    "# #         s =[]\n",
    "# #         p = np.matmul(self.weights[nLayers][\"weights\"][0], l)\n",
    "# #         s.append(p)\n",
    "# #         q = af(p)\n",
    "# #         t.append(s)        \n",
    "        \n",
    "# #         return t,r\n",
    "\n",
    "#     def backprop(self, d, data):\n",
    "#         der = []\n",
    "#         #t,r= self.feedforward(data)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         t,r,q = self.predict(data)\n",
    "        \n",
    "#         for i in range(self.nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(self.nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = []\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[nLayers][0]))\n",
    "#         diff.append(d - q)\n",
    "#         der.append(s)\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer = self.weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(self.weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(self.weights[i + 1]['weights'])):\n",
    "#                         error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff[0])\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "#         for j in range(len(self.weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "# import numpy as np\n",
    "\n",
    "# #np.random.seed(100)\n",
    "\n",
    "\n",
    "# # Sigmoid is the activation Function\n",
    "# def af(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def af_derivative(p):\n",
    "#     return af(p) * (1 -af(p))\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             #p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         y = af(y)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, ep = 0):\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         self.ep = ep\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "# #         newdata = []\n",
    "# #         for i in range(len(x)):\n",
    "# #             newdata.append(np.append(x[i],1))     \n",
    "# #         self.data = newdata\n",
    "#         self.data = x\n",
    "        \n",
    "        \n",
    "#         self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}] #create the weights from the inputs to the first layer\n",
    "#         for i in range(self.nLayers-1):\n",
    "#             self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers > 0:\n",
    "            \n",
    "#             self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes)}) #create weights from final layer to output node\n",
    "#         #return self.weights\n",
    "#         self.train()\n",
    " \n",
    "\n",
    "        \n",
    "#     def train(self):\n",
    "        \n",
    "\n",
    "#         #print(np.asarray(self.data))\n",
    "# #         print(self.labels)\n",
    "#         #temp_weights = self.weight_initialization()\n",
    "#         #print(self.weights)\n",
    "#         temp_eta = self.eta\n",
    "# #         temp2 = mse(self.data, self.labels, self.weights, self.nLayers, self.nNodes)\n",
    "# #         print(temp2)\n",
    "# #         print(f) \n",
    "#         e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "# #         epoch.append(e)\n",
    "# #         obj.append(temp2)\n",
    "#         cos = 100000000\n",
    "# #         #epd = 10000000\n",
    "#         while cos >= 0.1:\n",
    "#         #while cos >= 0.1:\n",
    "#             #print(cos)\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 #print(i)\n",
    "#                 self.backprop(self.labels[i], self.data[i]) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "\n",
    "#             cos = mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes)\n",
    "# #             epoch.append(e)\n",
    "# #             obj.append(cos)\n",
    "# #             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 cos = 100000000\n",
    "# #                 self.weights = temp_weights\n",
    "# #                 print(temp_weights)\n",
    "                \n",
    "#                 if self.eta <= 0.00001:                    \n",
    "#                     self.eta = temp_eta  \n",
    "# #                     obj =[]\n",
    "# #                     epoch = []\n",
    "# #                     e = 0\n",
    "# #                     cos = 100000000\n",
    "#                     self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}]\n",
    "#                     for i in range(self.nLayers-1):\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes)})\n",
    "#                     if self.nLayers >= 0:\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes)})                    \n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "#         #print(self.weights)\n",
    "#         return 0.0\n",
    "       \n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "# #         prev = np.append(x,1)\n",
    "#         r =[]\n",
    "        \n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             #l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         print(p)\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], l)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         t.append(s)\n",
    "#         #print(q)\n",
    "        \n",
    "#         return q\n",
    "#     def feedforward(self,x=[]):\n",
    "#         prev = x\n",
    "#         r =[]\n",
    "        \n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             #l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], l)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         t.append(s)        \n",
    "        \n",
    "#         return t,r\n",
    "        \n",
    "        \n",
    "#     def backprop(self, d, data):\n",
    "#         der = []\n",
    "#         #t,r= self.feedforward(data)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         t,r = self.feedforward(data)\n",
    "#         q = self.predict(data)\n",
    "        \n",
    "#         for i in range(self.nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(self.nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = []\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[nLayers][0]))\n",
    "#         diff.append(d - q)\n",
    "#         der.append(s)\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer = self.weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(self.weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(self.weights[i + 1]['weights'])):\n",
    "#                         error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff[0])\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "#         for j in range(len(self.weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "\n",
    "# import numpy as np\n",
    "# #np.random.seed(100)\n",
    "\n",
    "# # Sigmoid is the activation Function\n",
    "# def af(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def af_derivative(p):\n",
    "#     return af(p) * (1 -af(p))\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000):\n",
    "#         self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         #self.ep = ep\n",
    "#         #self.train()\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "#         self.data = newdata\n",
    "#         self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}] #create the weights from the inputs to the first layer\n",
    "#         for i in range(self.nLayers-1):\n",
    "#             self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers > 0:\n",
    "            \n",
    "#             self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)}) #create weights from final layer to output node\n",
    "#         #return self.weights\n",
    "        \n",
    "        \n",
    "#     def train(self):\n",
    "#         print(self.weights)\n",
    "#         temp_eta = self.eta\n",
    "#         temp_weights = self.weights\n",
    "#         temp2 = mse(self.data, self.labels, self.weights, self.nLayers, self.nNodes)\n",
    "#         print(temp2)\n",
    "#         e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "#         cos = 100000000\n",
    "#         while e < self.maxIt:\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 #print(self.data[i])\n",
    "#                 self.backprop(self.labels[i], self.data[i]) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "# #                 print(self.weights)\n",
    "# #                 print(f)\n",
    "\n",
    "\n",
    "\n",
    "#             cos = mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes)\n",
    "\n",
    "# #             epoch.append(e)\n",
    "# #             obj.append(cos)\n",
    "# #             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 if self.eta <= 0.00001:\n",
    "                    \n",
    "#                     self.eta = temp_eta  \n",
    "                    \n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 self.weights = temp_weights                \n",
    "#                 cos = 100000000\n",
    "\n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "\n",
    "#         #print(self.weights)\n",
    "#         return self.weights, obj, epoch   \n",
    "       \n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "        \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         #q = af(p)\n",
    "#         return p\n",
    "        \n",
    "#     def feedforward(self, data):\n",
    "#         r =[]\n",
    "#         prev = data\n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.dot(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         p = np.dot(self.weights[nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         t.append(s)        \n",
    "        \n",
    "#         return t,r\n",
    "\n",
    "#     def backprop(self, d, data):\n",
    "#         der = []\n",
    "#         t,r= self.feedforward(data)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         q = self.predict(data)\n",
    "        \n",
    "#         for i in range(self.nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(self.nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = d-q\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[nLayers][0]))\n",
    "#         der.append(s)\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer = self.weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(self.weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(self.weights[i + 1]['weights'])):\n",
    "#                         error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff)\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "#         for j in range(len(self.weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the _init_(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "\n",
    "# import numpy as np\n",
    "# np.random.seed(100)\n",
    "\n",
    "# def sigmoid(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def sigmoid_derivative(v):\n",
    "#     f_v = sigmoid(v)\n",
    "#     return f_v * (1 - f_v) * v\n",
    "\n",
    "# class NeuralNetwork:\n",
    "\n",
    "#     #Do not change this function header\n",
    "#     def _init_(self,x=[[]],y=[],numLayers=2,numNodes=2,eta=0.001,maxIter=10000):\n",
    "#         self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "\n",
    "#         # Other useful variables\n",
    "#         self.num_samples = len(self.data)\n",
    "#         self.num_features = len(self.data[0])\n",
    "\n",
    "#         # List for storing weights of each layer\n",
    "#         self.weights = list()\n",
    "#         # First hidden layer weights\n",
    "#         self.weights.append(self.get_weights(size=(self.num_features, self.nNodes)))\n",
    "#         # Other hidden layer weights\n",
    "#         for i in range(self.nLayers - 1):\n",
    "#             self.weights.append(self.get_weights(size=(self.nNodes, self.nNodes)))\n",
    "#         # Output layer weights\n",
    "#         self.weights.append(self.get_weights(size=(self.nNodes, 1)))\n",
    "\n",
    "#         self.train()\n",
    "\n",
    "#     def get_weights(self, size: tuple):\n",
    "#         # Drawing samples from LeCun normal distribution\n",
    "#         # Source: https://arxiv.org/pdf/1706.02515.pdf\n",
    "#         return np.random.normal(loc=0, scale=(1/size[0]), size=size)\n",
    "\n",
    "#     def train(self):\n",
    "#         for sample, label in zip(self.data, self.labels):\n",
    "#             sample = np.array(sample).reshape((self.num_features, 1))\n",
    "#             linear_activations, non_linear_activations = self.feedforward(sample)\n",
    "#             predicted = non_linear_activations[-1]\n",
    "#             initial_error = predicted - label\n",
    "#             layer_delta = self.backprop(linear_activations, initial_error)\n",
    "#             self.update_weights(sample, non_linear_activations, layer_delta)\n",
    "\n",
    "#     def update_weights(self, initial_input, non_linear_activations, layer_delta):\n",
    "#         current_input = initial_input\n",
    "#         for i in range(len(self.weights)):\n",
    "#             w_i = self.weights[i]\n",
    "#             update = self.eta * current_input.dot(layer_delta[i].T)\n",
    "#             self.weights[i] = w_i - update\n",
    "#             current_input = non_linear_activations.pop(0)\n",
    "\n",
    "#     def predict(self, x=[]):\n",
    "#         x = np.array(x).reshape((self.num_features, 1))\n",
    "#         return self.feedforward(x)[1][-1]\n",
    "\n",
    "#     def feedforward(self, x_i):\n",
    "#         current_input = x_i\n",
    "#         linear_activations = list()\n",
    "#         non_linear_activations = list()\n",
    "#         for weight in self.weights:\n",
    "#             z = weight.T.dot(current_input)\n",
    "#             a = sigmoid(z)\n",
    "#             linear_activations.append(z)\n",
    "#             non_linear_activations.append(a)\n",
    "#             current_input = a\n",
    "#         return linear_activations, non_linear_activations\n",
    "\n",
    "#     def backprop(self, linear_activations, initial_error):\n",
    "#         current_error = initial_error\n",
    "#         layer_delta = list()\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer_w = self.weights[i + 1] if i + 1 < len(self.weights) else np.array([[1]])\n",
    "#             delta = layer_w.dot(current_error) * sigmoid_derivative(linear_activations[i])\n",
    "#             layer_delta.insert(0, delta)\n",
    "#             current_error = delta\n",
    "#         return layer_delta\n",
    "\n",
    "\n",
    "# #if _name_ == '_main_':\n",
    "# x_data = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "# y_data = [0, 1, 1, 0]\n",
    "# nn_regressor = NeuralNetwork(x_data, y_data, maxIter=10000)\n",
    "# print(y_data)\n",
    "# print([nn_regressor.predict(x) for x in x_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The commented variables are suggestions so change them as appropriate,\n",
    "#However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "#You may create additional functions as you see fit\n",
    "\n",
    "import numpy as np\n",
    "#np.random.seed(100)\n",
    "\n",
    "\n",
    "# Sigmoid is the activation Function\n",
    "def af(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "def af_derivative(p):\n",
    "    return af(p) * (1 -af(p))\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "#np.random.seed(100)\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, ep = 0):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        self.nLayers = numLayers\n",
    "        self.nNodes = numNodes\n",
    "        self.numOutputs = numOutputs\n",
    "        self.eta = eta\n",
    "        self.maxIt = maxIter\n",
    "        self.ep = ep\n",
    "        #self.train()\n",
    "        #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "#         self.data = newdata\n",
    "        self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}] #create the weights from the inputs to the first layer\n",
    "        for i in range(self.nLayers-1):\n",
    "            self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes)}) #create the random weights between internal layers\n",
    "            \n",
    "        if self.nLayers > 0:\n",
    "            \n",
    "            self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes)}) #create weights from final layer to output node\n",
    "        #return self.weights\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "\n",
    "        print(self.data)\n",
    "        #temp_weights = self.weight_initialization()\n",
    "        print(self.weights)\n",
    "#         temp_eta = self.eta\n",
    "#         temp2 = mse(self.data, self.labels, self.weights, self.nLayers, self.nNodes)\n",
    "#         print(temp2)\n",
    "#         print(f) \n",
    "        e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "#         epoch.append(e)\n",
    "#         obj.append(temp2)\n",
    "#         cos = 100000000\n",
    "#         #epd = 10000000\n",
    "        while e < self.maxIt:\n",
    "            #print(cos)\n",
    "            #prev = cos\n",
    "            for i in range(len(self.data)):\n",
    "                #print(i)\n",
    "                self.backprop(self.labels[i], self.data[i]) \n",
    "                for m in range(len(self.weights)):\n",
    "                    for j in range(len(self.weights[m]['weights'])):\n",
    "                        for k in range(len(self.weights[m]['weights'][j])):\n",
    "                            self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "#                 print('\\n')\n",
    "#                 print(self.weights)\n",
    "#                 print(f)\n",
    "\n",
    "\n",
    "            #cos = mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes)\n",
    "            e += 1\n",
    "#             epoch.append(e)\n",
    "#             obj.append(cos)\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 if self.eta <= 0.00001:\n",
    "                    \n",
    "#                     self.eta = temp_eta  \n",
    "#                     #print(self.eta)\n",
    "                    \n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 epoch.append(e)\n",
    "#                 #print(temp_weights)\n",
    "#                 temp_mse = mse(self.data, self.labels, temp_weights, self.nLayers,self.nNodes)\n",
    "#                 obj.append(temp_mse)\n",
    "#                 #print(temp_mse)                \n",
    "#                 cos = 100000000\n",
    "#                 #epd = 100000000\n",
    "\n",
    "#             elif cos <= prev:\n",
    "#                 e += 1\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 #epd = abs(cos - prev)\n",
    "#                 #print(g)\n",
    "        #print(self.weights)\n",
    "        return self.weights   \n",
    "       \n",
    "\n",
    "    def predict(self,x=[]):\n",
    "        prev = x\n",
    "        for j in range(self.nLayers):\n",
    "            l = []\n",
    "            s = []\n",
    "            for m in range(self.nNodes):\n",
    "                s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "            for k in s:\n",
    "                l.append(af(k))\n",
    "            #l.append(1)\n",
    "            prev = np.asarray(l)\n",
    "        \n",
    "        s =[]\n",
    "        p = np.matmul(self.weights[self.nLayers][\"weights\"][0], prev)\n",
    "        s.append(p)\n",
    "        q = af(p)\n",
    "        return q\n",
    "        \n",
    "    def feedforward(self, data):\n",
    "        r =[]\n",
    "        prev = data\n",
    "        r.append(prev)\n",
    "        t =[]\n",
    "\n",
    "        for j in range(self.nLayers):\n",
    "            l = []\n",
    "            s = []\n",
    "            for m in range(self.nNodes):\n",
    "                #print(self.weights[j][\"weights\"][m])\n",
    "                s.append(np.dot(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "            for k in s:\n",
    "                l.append(af(k))\n",
    "            #l.append(1)\n",
    "            prev = np.asarray(l)\n",
    "            t.append(s)\n",
    "            r.append(l)\n",
    "            \n",
    "        s =[]\n",
    "        p = np.dot(self.weights[nLayers][\"weights\"][0], l)\n",
    "        s.append(p)\n",
    "        q = af(p)\n",
    "        t.append(s)        \n",
    "        \n",
    "        return t,r\n",
    "\n",
    "    def backprop(self, d, data):\n",
    "        der = []\n",
    "        t,r= self.feedforward(data)\n",
    "#         print('\\n')\n",
    "#         print(\"t = \" + str(t))\n",
    "#         print('\\n')\n",
    "#         print('r = ' + str(r))  \n",
    "        q = self.predict(data)\n",
    "        \n",
    "        for i in range(self.nLayers):\n",
    "            a =[]\n",
    "            for m in range(self.nNodes):\n",
    "                a.append(af_derivative(t[i][m]))\n",
    "            der.append(a)\n",
    "        \n",
    "        diff = []\n",
    "        s =[]\n",
    "        s.append(af_derivative(t[nLayers][0]))\n",
    "        diff.append(d - q)\n",
    "        der.append(s)\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            layer = self.weights[i]\n",
    "            errors = []\n",
    "            if i != len(self.weights)-1:\n",
    "                for j in range(len(layer['weights'])):\n",
    "                    error = 0\n",
    "                    \n",
    "                    for k in range(len(self.weights[i + 1]['weights'])):\n",
    "                        error = (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "                    errors.append(error)\n",
    "            else:\n",
    "                errors.append(diff[0])\n",
    "            layer['s'] = []\n",
    "            for j in range(len(layer['weights'])):\n",
    "                layer['s'].append(errors[j]*der[i][j])\n",
    "#         print('\\n')\n",
    "        #print(weights)\n",
    "        #print(f)\n",
    "        for j in range(len(self.weights)):\n",
    "            layer = self.weights[j]\n",
    "            layer['g'] = []\n",
    "            for k in range(len(self.weights[j]['weights'])):\n",
    "                s =[]\n",
    "                for m in range(len(self.weights[j]['weights'][k])):\n",
    "                    s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "                layer['g'].append(s)\n",
    "\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The commented variables are suggestions so change them as appropriate,\n",
    "# #However, do not change the __init__(), train(), or predict(x=[]) function headers\n",
    "# #You may create additional functions as you see fit\n",
    "\n",
    "# import numpy as np\n",
    "# #np.random.seed(100)\n",
    "\n",
    "# def sigmoid(t):\n",
    "#     return 1 / (1 + np.exp(-t))\n",
    "\n",
    "# def sigmoid_derivative(p):\n",
    "#     return sigmoid(p) * (1 -sigmoid(p))\n",
    "\n",
    "# class NeuralNetwork:\n",
    "\n",
    "#     #Do not change this function header\n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000):\n",
    "#         self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         self.weights = [{\"weights\":np.random.rand(numNodes, len(x[0]))}] #create the weights from the inputs to the first layer\n",
    "       \n",
    "#         for i in range(self.nLayers-1):\n",
    "#             self.weights.append({\"weights\":np.random.rand(numNodes,numNodes)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers > 0:           \n",
    "#             self.weights.append({\"weights\":np.random.rand(numOutputs,numNodes)}) #create weights from final layer to output node\n",
    "#         self.outputs = np.zeros(y.shape)\n",
    "\n",
    "                \n",
    "#     def train(self):\n",
    "#         np.random.shuffle(self.data)\n",
    "#         print(self.weights)\n",
    "#         for e in  range(self.maxIt):           \n",
    "#             for i in range(len(self.data)):\n",
    "#                 self.backprop(self.labels[i], self.data[i], self.weights, self.nLayers, self.nNodes) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] += (self.eta * self.weights[m]['g'][j][k])\n",
    "#                 print('\\n')\n",
    "#                 print(self.weights)\n",
    "#                 print(f)\n",
    "#         return self.weights\n",
    "\n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "#             for k in s:\n",
    "#                 l.append(sigmoid(k))\n",
    "#             prev = np.asarray(l)\n",
    "        \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         q = sigmoid(p)\n",
    "#         return q\n",
    "\n",
    "#     def feedforward(self, data, weights, nLayers, nNodes):\n",
    "#         r =[]\n",
    "#         prev = data\n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "#         for j in range(nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(nNodes):\n",
    "#                 s.append(np.dot(weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(sigmoid(k))\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "        \n",
    "#         s =[]\n",
    "#         p = np.dot(weights[nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         #p = sigmoid(p)\n",
    "#         t.append(s)              \n",
    "#         return t,r\n",
    "\n",
    "#     def backprop(self, d, data, weights, nLayers, nNodes):\n",
    "#         der = []\n",
    "#         t,r = self.feedforward(data, weights, nLayers, nNodes) \n",
    "#         print('\\n')\n",
    "#         print(\"t = \" + str(t))\n",
    "#         print('\\n')\n",
    "#         print('r = ' + str(r))\n",
    "#         q = self.predict(data)\n",
    "#         for i in range(nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(nNodes):\n",
    "#                 a.append(sigmoid_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = d-q\n",
    "#         s =[]\n",
    "#         s.append(sigmoid_derivative(t[nLayers][0]))\n",
    "#         der.append(s)\n",
    "#         print(der)\n",
    "#         print(diff)\n",
    "#         for i in reversed(range(len(weights))):\n",
    "#             layer = weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0                    \n",
    "#                     for k in range(len(weights[i + 1]['weights'])):\n",
    "#                         error += (weights[i + 1]['weights'][k][j] * weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff)             \n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "#         print(self.weights)\n",
    "       \n",
    "#         for j in range(len(weights)):\n",
    "#             layer = weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(layer['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(layer['weights'][k])):\n",
    "#                     #print(self.weights[j]['s'][k])\n",
    "#                     s.append((((r[j][m])*layer['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "#         print('\\n')\n",
    "#         print('G')\n",
    "#         print(self.weights)\n",
    "#         return 0.0\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
